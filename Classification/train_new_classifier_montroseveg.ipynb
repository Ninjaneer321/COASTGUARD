{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train  a new classifier for VegSat\n",
    "\n",
    "In this notebook the VegSat classifier is trained using satellite images from new sites. This can improve the accuracy of the veg edge detection if the users are experiencing issues with the default classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Sites for training:\n",
      "['MONTROSE.kml']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os, sys\n",
    "import glob\n",
    "import numpy as np\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.use('Qt5Agg')\n",
    "from matplotlib import gridspec\n",
    "import matplotlib.dates as mdates\n",
    "plt.ion()\n",
    "from datetime import datetime, timezone, timedelta\n",
    "\n",
    "from Toolshed import Download, Image_Processing, Shoreline, Toolbox, Transects, VegetationLine\n",
    "\n",
    "import mpl_toolkits as mpl\n",
    "from mpl_toolkits.axes_grid1.inset_locator import zoomed_inset_axes, mark_inset\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "import seaborn as sns; sns.set()\n",
    "import math\n",
    "import geemap\n",
    "import ee\n",
    "import pprint\n",
    "from shapely import geometry\n",
    "from shapely.geometry import Point, LineString\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.cm as cm\n",
    "import pyproj\n",
    "from IPython.display import clear_output\n",
    "import scipy\n",
    "from scipy import optimize\n",
    "import csv\n",
    "import math\n",
    "\n",
    "# sklearn modules\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import sklearn\n",
    "if sklearn.__version__[:4] == '0.20':\n",
    "    from sklearn.externals import joblib\n",
    "else:\n",
    "    import joblib\n",
    "\n",
    "# coastsat modules\n",
    "sys.path.insert(0, os.pardir)\n",
    "\n",
    "ee.Initialize()\n",
    "\n",
    "# plotting params\n",
    "plt.rcParams['font.size'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "plt.rcParams['axes.titlesize'] = 12\n",
    "plt.rcParams['axes.labelsize'] = 12\n",
    "\n",
    "# filepaths \n",
    "filepath_images = os.path.join(os.getcwd(), 'data')\n",
    "filepath_train = os.path.join(os.getcwd(), 'training_data')\n",
    "filepath_models = os.path.join(os.getcwd(), 'models')\n",
    "\n",
    "# settings\n",
    "settings ={'filepath_train':filepath_train, # folder where the labelled images will be stored\n",
    "           'cloud_thresh':0.9, # percentage of cloudy pixels accepted on the image\n",
    "           'cloud_mask_issue':False, # set to True if problems with the default cloud mask \n",
    "           'inputs':{'filepath':filepath_images}, # folder where the images are stored\n",
    "           'labels':{'veg':1,'non-veg':2}, # labels for the classifier\n",
    "           'colors':{'veg':[0.3, 0.65, 0.3],'non-veg':[0.58,0.51,0.8]},\n",
    "           'tolerance':0.01, # this is the pixel intensity tolerance, when using flood fill for sandy pixels\n",
    "                             # set to 0 to select one pixel at a time\n",
    "            }\n",
    "        \n",
    "# read kml files for the training sites\n",
    "filepath_sites = os.path.join(os.getcwd(), 'training_sites')\n",
    "#train_sites = [os.path.basename(x) for x in glob.glob(filepath_sites+'/*.kml')]\n",
    "train_sites = [os.path.basename(x) for x in glob.glob(filepath_sites+'/MONTROSE.kml')]\n",
    "print('Sites for training:\\n%s\\n'%train_sites)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Download images\n",
    "\n",
    "For each site on which you want to train the classifier, save a .kml file with the region of interest (5 vertices clockwise, first and last points are the same, can be created from Google myMaps) in the folder *\\training_sites*.\n",
    "\n",
    "You only need a few images (~10) to train the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Point' object has no attribute 'exterior'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_849313/1074898004.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msite\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_sites\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mpolygon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mToolbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolygon_from_kml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_sites\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mpolygon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mToolbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmallest_rectangle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolygon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0msitename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msite\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0msite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     inputs = {'polygon':polygon, 'dates':dates, 'sat_list':sat_list,\n",
      "\u001b[0;32m~/PhD/Year2/ModelsFrameworks/CoastWatch-main/Elves/Toolbox.py\u001b[0m in \u001b[0;36msmallest_rectangle\u001b[0;34m(polygon)\u001b[0m\n\u001b[1;32m    731\u001b[0m     \u001b[0mmultipoints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgeometry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPolygon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolygon\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m     \u001b[0mpolygon_geom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmultipoints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvelope\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 733\u001b[0;31m     \u001b[0mcoords_polygon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolygon_geom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexterior\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    734\u001b[0m     \u001b[0mpolygon_rect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcoords_polygon\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpolygon_rect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Point' object has no attribute 'exterior'"
     ]
    }
   ],
   "source": [
    "# dowload images at the sites\n",
    "dates = ['2019-01-01', '2019-07-01']\n",
    "sat_list = ['S2']\n",
    "for site in train_sites:\n",
    "    polygon = Toolbox.polygon_from_kml(os.path.join(filepath_sites,site))\n",
    "    \n",
    "    polygon = Toolbox.smallest_rectangle(polygon)\n",
    "    sitename = site[:site.find('.')]  \n",
    "    inputs = {'polygon':polygon, 'dates':dates, 'sat_list':sat_list,\n",
    "             'sitename':sitename, 'filepath':filepath_images}\n",
    "    print(sitename)\n",
    "    metadata = Download.retrieve_images(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "##ST ANDREWS EAST\n",
    "sitename = 'Montrose'\n",
    "lonmin, lonmax = -2.49, -2.42\n",
    "latmin, latmax = 56.70, 56.75\n",
    "\n",
    "#point = ee.Geometry.Point([lonmin, latmin]) \n",
    "if latmin > latmax:\n",
    "    print('Check your latitude min and max bounding box values!')\n",
    "    oldlatmin = latmin\n",
    "    oldlatmax = latmax\n",
    "    latmin = oldlatmax\n",
    "    latmax = oldlatmin\n",
    "if lonmin > lonmax:\n",
    "    print('Check your longitude min and max bounding box values!')\n",
    "    oldlonmin = lonmin\n",
    "    oldlonmax = lonmax\n",
    "    lonmin = oldlonmax\n",
    "    lonmax = oldlonmin\n",
    "    \n",
    "polygon = [[[lonmin, latmin],[lonmax, latmin],[lonmin, latmax],[lonmax, latmax]]]\n",
    "point = ee.Geometry.Point(polygon[0][0]) \n",
    "polygon = Toolbox.smallest_rectangle(polygon)\n",
    "\n",
    "filepath = os.path.join(os.getcwd(), 'Data')\n",
    "direc = os.path.join(filepath, sitename)\n",
    "\n",
    "if os.path.isdir(direc) is False:\n",
    "    os.mkdir(direc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images available between 2019-05-01 and 2019-07-01:\n",
      "- In Landsat Tier 1 & Sentinel-2 Level-1C:\n",
      "  S2: 16 images\n",
      "  Total: 16 images\n"
     ]
    }
   ],
   "source": [
    "sat_list = ['S2']\n",
    "dates = ['2019-05-01', '2019-07-01']\n",
    "projection_epsg = 27700\n",
    "image_epsg = 32630\n",
    "\n",
    "# filepaths \n",
    "filepath_images = os.path.join(os.getcwd(), 'Data')\n",
    "filepath_train = os.path.join(os.getcwd(), 'training_data')\n",
    "filepath_models = os.path.join(os.getcwd(), 'models')\n",
    "\n",
    "# put all the inputs into a dictionnary\n",
    "inputs = {\n",
    "    'polygon': polygon,\n",
    "    'dates': dates, \n",
    "    'daterange':dates, \n",
    "    'sat_list': sat_list, \n",
    "    'sitename': sitename, \n",
    "    'filepath':filepath_images\n",
    "}\n",
    "\n",
    "Download.check_images_available(inputs)\n",
    "\n",
    "\n",
    "#settings = {\n",
    "#    'filepath_train':filepath_train, # folder where the labelled images will be stored\n",
    "#    'labels':{'sand':1,'white-water':2,'water':3,'vegetation':4,'urban':5}, # labels for the classifier\n",
    "#    'colors':{'sand':[1, 0.65, 0],'white-water':[1,0,1],'water':[0.1,0.1,0.7],'other land features':[0.8,0.8,0.1]},\n",
    "settings = {\n",
    "    'filepath_train':filepath_train, # folder where the labelled images will be stored\n",
    "    'labels':{'veg':1,'nonveg':2}, # labels for the classifier\n",
    "    'colors':{'veg':[0.2,0.8,0.2],'nonveg':[0.39,0.58,0.93]},\n",
    "    'tolerance':0.01, # this is the pixel intensity tolerance, when using flood fill for sandy pixels\n",
    "                             # set to 0 to select one pixel at a time\n",
    "    'ref_epsg': 4326,\n",
    "    'max_dist_ref': 500,\n",
    "    # general parameters:\n",
    "    'cloud_thresh': 0.9,        # threshold on maximum cloud cover\n",
    "    'output_epsg': image_epsg,     # epsg code of spatial reference system desired for the output   \n",
    "    # quality control:\n",
    "    'check_detection': True,    # if True, shows each shoreline detection to the user for validation\n",
    "    'adjust_detection': True,  # if True, allows user to adjust the postion of each shoreline by changing the threhold\n",
    "    'save_figure': True,        # if True, saves a figure showing the mapped shoreline for each image\n",
    "    # [ONLY FOR ADVANCED USERS] shoreline detection parameters:\n",
    "    'min_beach_area': 200,     # minimum area (in metres^2) for an object to be labelled as a beach\n",
    "    'buffer_size': 250,         # radius (in metres) for buffer around sandy pixels considered in the shoreline detection\n",
    "    'min_length_sl': 500,       # minimum length (in metres) of shoreline perimeter to be valid\n",
    "    'cloud_mask_issue': True,  # switch this parameter to True if sand pixels are masked (in black) on many images  \n",
    "    'sand_color': 'bright',    # 'default', 'dark' (for grey/black sand beaches) or 'bright' (for white sand beaches)\n",
    "    # add the inputs defined previously\n",
    "    'inputs': inputs,\n",
    "    'projection_epsg': projection_epsg,\n",
    "    'hausdorff_threshold':3*(10**50)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata already exists and was loaded\n"
     ]
    }
   ],
   "source": [
    "Sat = Toolbox.image_retrieval(inputs)\n",
    "metadata = Toolbox.metadata_collection(sat_list, Sat, filepath, sitename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Label images\n",
    "\n",
    "Label the images into 2 classes: veg, non-veg.\n",
    "\n",
    "The labelled images are saved in the *filepath_train* and can be visualised afterwards for quality control. If yo make a mistake, don't worry, this can be fixed later by deleting the labelled image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "code_folding": [],
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "# label the images with an interactive annotator\n",
    "%matplotlib qt\n",
    "for site in train_sites:\n",
    "    settings['inputs']['sitename'] = sitename\n",
    "    settings['cloud_mask_issue'] = False\n",
    "    # label images\n",
    "    Classifier.label_vegimages(metadata, polygon, Sat, settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train Classifier\n",
    "\n",
    "A Multilayer Perceptron is trained with *scikit-learn*. To train the classifier, the training data needs to be loaded.\n",
    "\n",
    "You can use the data that was labelled here and/or the original CoastSat training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pixels per class in training data:\n",
      "veg : 0 pixels\n",
      "nonveg : 0 pixels\n"
     ]
    }
   ],
   "source": [
    "# load labelled images\n",
    "features = Classifier.load_labels(train_sites, settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can also load the original CoastSat training data (and optionally merge it with your labelled data)\n",
    "with open(os.path.join(settings['filepath_train'], 'CoastSat_training_set_L8.pkl'), 'rb') as f:\n",
    "    features_original = pickle.load(f)\n",
    "for key in features_original.keys():\n",
    "    print('%s : %d pixels'%(key,len(features_original[key])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this section to combine the original training data with your labelled data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# add the white-water data from the original training data\n",
    "features['white-water'] = np.append(features['white-water'], features_original['white-water'], axis=0)\n",
    "# or merge all the classes\n",
    "# for key in features.keys():\n",
    "#     features[key] = np.append(features[key], features_original[key], axis=0)\n",
    "#features = features_original \n",
    "for key in features.keys():\n",
    "    print('%s : %d pixels'%(key,len(features[key])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[OPTIONAL] As the classes do not have the same number of pixels, it is good practice to subsample the very large classes (in this case 'water' and 'other land features'):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'water'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_849313/788913652.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'water'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'other land features'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m# print classes again\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'water'"
     ]
    }
   ],
   "source": [
    "# subsample randomly the land and water classes\n",
    "# as the most important class is 'sand', the number of samples should be close to the number of sand pixels\n",
    "n_samples = 5000\n",
    "for key in ['water', 'other land features']:\n",
    "    features[key] =  features[key][np.random.choice(features[key].shape[0], n_samples, replace=False),:]\n",
    "# print classes again\n",
    "for key in features.keys():\n",
    "    print('%s : %d pixels'%(key,len(features[key])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the labelled data is ready, format it into X, a matrix of features, and y, a vector of labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "# format into X (features) and y (labels) \n",
    "classes = ['veg','nonveg']\n",
    "labels = [1,2]\n",
    "X,y = SDS_classify.format_training_data(features, classes, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide the dataset into train and test: train on 70% of the data and evaluate on the other 30%:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "# divide in train and test and evaluate the classifier\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True, random_state=0)\n",
    "classifier = MLPClassifier(hidden_layer_sizes=(100,50), solver='adam')\n",
    "classifier.fit(X_train,y_train)\n",
    "print('Accuracy: %0.4f' % classifier.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[OPTIONAL] A more robust evaluation is 10-fold cross-validation (may take a few minutes to run):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "# cross-validation\n",
    "scores = cross_val_score(classifier, X, y, cv=10)\n",
    "print('Accuracy: %0.4f (+/- %0.4f)' % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "[1::2]# plot confusion matrix\n",
    "%matplotlib inline\n",
    "y_pred = classifier.predict(X_test)\n",
    "SDS_classify.plot_confusion_matrix(y_test, y_pred,\n",
    "                                   classes=['other land features','sand','white-water','water'],\n",
    "                                   normalize=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When satisfied with the accuracy and confusion matrix, train the model using ALL the training data and save it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train with all the data and save the final classifier\n",
    "classifier = MLPClassifier(hidden_layer_sizes=(100,50), solver='adam')\n",
    "classifier.fit(X,y)\n",
    "joblib.dump(classifier, os.path.join(filepath_models, 'NN_4classes_Landsat_test.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Evaluate the classifier\n",
    "\n",
    "Load a classifier that you have trained (specify the classifiers filename) and evaluate it on the satellite images.\n",
    "\n",
    "This section will save the output of the classification for each site in a directory named \\evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and evaluate a classifier\n",
    "%matplotlib qt\n",
    "classifier = joblib.load(os.path.join(filepath_models, 'NN_4classes_Landsat_test.pkl'))\n",
    "settings['output_epsg'] = 3857\n",
    "settings['min_beach_area'] = 4500\n",
    "settings['buffer_size'] = 200\n",
    "settings['min_length_sl'] = 200\n",
    "settings['cloud_thresh'] = 0.5\n",
    "# visualise the classified images\n",
    "for site in train_sites:\n",
    "    settings['inputs']['sitename'] = site[:site.find('.')] \n",
    "    # load metadata\n",
    "    metadata = SDS_download.get_metadata(settings['inputs'])\n",
    "    # plot the classified images\n",
    "    SDS_classify.evaluate_classifier(classifier,metadata,settings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
