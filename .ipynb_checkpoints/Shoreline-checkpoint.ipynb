{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CoastWatch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import matplotlib\n",
    "matplotlib.use('Qt5Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "plt.ion()\n",
    "import pandas as pd\n",
    "from datetime import datetime, timezone, timedelta\n",
    "from Elves import Download, Image_Processing, Shoreline, Toolbox, Transects, VegetationLine\n",
    "import mpl_toolkits as mpl\n",
    "from mpl_toolkits.axes_grid1.inset_locator import zoomed_inset_axes, mark_inset\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import matplotlib.dates as mdates\n",
    "from sklearn.datasets import load_diabetes\n",
    "import seaborn as sns; sns.set()\n",
    "import math\n",
    "import geemap\n",
    "import ee\n",
    "import pprint\n",
    "from shapely import geometry\n",
    "from shapely.geometry import Point, LineString\n",
    "import geopandas as gpd\n",
    "import matplotlib.cm as cm\n",
    "import pyproj\n",
    "from IPython.display import clear_output\n",
    "import scipy\n",
    "from scipy import optimize\n",
    "import csv\n",
    "import math\n",
    "\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Region of Interest Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two options for image retrieval: 1st involes selecting region for the map generated below; 2nd involes inputting lat,lon coords manually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Option 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7677f03ae0243f8adf7c5f3051be4af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[0, 0], controls=(WidgetControl(options=['position', 'transparent_bg'], widget=HBox(children=(Togglâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Run this cell to generate a map. Use the polygon drawing tool on the left-hand side to \n",
    "draw out the region of coast you're interested in.\n",
    "\"\"\"\n",
    "\n",
    "Map = geemap.Map(center=[0,0],zoom=2)\n",
    "Map.add_basemap('HYBRID')\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi = Map.user_roi.geometries().getInfo()[0]['coordinates']\n",
    "polygon = [[roi[0][0],roi[0][3],roi[0][1],roi[0][2]]]\n",
    "point = ee.Geometry.Point(roi[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Option 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##Below are example coordinates\n",
    "\n",
    "##ST ANDREWS\n",
    "#lonmin, lonmax = -2.842023, -2.774955\n",
    "#latmin, latmax = 56.338343, 56.368490\n",
    "\n",
    "##FELIXSTOWE\n",
    "lonmin, lonmax = 1.316128, 1.370888\n",
    "latmin, latmax = 51.930771, 51.965265\n",
    "\n",
    "##BAY OF SKAILL\n",
    "#lonmin, lonmax = -3.351555, -3.332693\n",
    "#latmin, latmax = 59.048456, 59.057759\n",
    "\n",
    "##SHINGLE STREET\n",
    "#lonmin, lonmax = 1.446131, 1.460008\n",
    "#latmin, latmax = 52.027039, 52.037448\n",
    "\n",
    "\n",
    "point = ee.Geometry.Point([lonmin, latmin]) \n",
    "polygon = [[[lonmin, latmin],[lonmax, latmin],[lonmin, latmax],[lonmax, latmax]]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images available between 2021-04-01 and 2021-07-02:\n",
      "- In Landsat Tier 1 & Sentinel-2 Level-1C:\n",
      "  L5: 0 images\n",
      "  L8: 9 images\n",
      "  S2: 47 images\n",
      "  Total: 56 images\n",
      "- In Landsat Tier 2:\n",
      "  L5: 0 images\n",
      "  L8: 0 images\n",
      "  Total: 0 images\n"
     ]
    }
   ],
   "source": [
    "# it's recommended to convert the polygon to the smallest rectangle (sides parallel to coordinate axes)       \n",
    "polygon = Toolbox.smallest_rectangle(polygon)\n",
    "\n",
    "# date range\n",
    "dates = ['2021-04-01', '2021-07-02']\n",
    "# satellite missions\n",
    "# Input a list of containing any/all of 'L5', 'L8', 'S2'\n",
    "sat_list = ['L5','L8','S2']\n",
    "\n",
    "projection_epsg = 27700\n",
    "image_epsg = 32630\n",
    "\n",
    "# name of the site\n",
    "sitename = 'Test_Shore2'\n",
    "# directory where the data will be stored\n",
    "filepath = os.path.join(os.getcwd(), 'Data')\n",
    "\n",
    "# put all the inputs into a dictionnary\n",
    "inputs = {'polygon': polygon, 'dates': dates, 'sat_list': sat_list, 'sitename': sitename, 'filepath':filepath}\n",
    "\n",
    "direc = os.path.join(filepath, sitename)\n",
    "\n",
    "if os.path.isdir(direc) is False:\n",
    "    os.mkdir(direc)\n",
    "\n",
    "# before downloading the images, check how many images are available for your inputs\n",
    "Download.check_images_available(inputs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata already exists and was loaded\n"
     ]
    }
   ],
   "source": [
    "Sat = Toolbox.image_retrieval(point,dates, sat_list)\n",
    "metadata = Toolbox.metadata_collection(sat_list, Sat, filepath, sitename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next 2 sections are for extracting the shoreline and vegetation edge respectively. (No need to do shoreline before veg edge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shoreline Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BasePath = 'Data/' + sitename + '/Shorelines'\n",
    "\n",
    "if os.path.isdir(BasePath) is False:\n",
    "    os.mkdir(BasePath)\n",
    "\n",
    "settings = {\n",
    "    # general parameters:\n",
    "    'cloud_thresh': 0.4,        # threshold on maximum cloud cover\n",
    "    'output_epsg': projection_epsg,#metadata[sat_list[0]]['epsg'][0], # epsg code of spatial reference system desired for the output   \n",
    "    'projection_epsg': projection_epsg,\n",
    "    # quality control:\n",
    "    'check_detection': True,    # if True, shows each shoreline detection to the user for validation\n",
    "    'adjust_detection': False,  # if True, allows user to adjust the postion of each shoreline by changing the threhold\n",
    "    'save_figure': True,        # if True, saves a figure showing the mapped shoreline for each image\n",
    "    # [ONLY FOR ADVANCED USERS] shoreline detection parameters:\n",
    "    'min_beach_area': 50,     # minimum area (in metres^2) for an object to be labelled as a beach\n",
    "    'buffer_size': 150,         # radius (in metres) for buffer around sandy pixels considered in the shoreline detection\n",
    "    'min_length_sl': 100,       # minimum length (in metres) of shoreline perimeter to be valid\n",
    "    'cloud_mask_issue': False,  # switch this parameter to True if sand pixels are masked (in black) on many images  \n",
    "    'sand_color': 'dark',   # 'default', 'dark' (for grey/black sand beaches) or 'bright' (for white sand beaches)\n",
    "    # add the inputs defined previously\n",
    "    'inputs': inputs,\n",
    "    'hausdorff_threshold':350000000\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Digitize a reference shoreline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference shoreline already exists and was loaded\n"
     ]
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "settings['reference_shoreline'] = Image_Processing.get_reference_sl(metadata, settings, polygon, dates)\n",
    "settings['max_dist_ref'] = 100 # max distance (in meters) allowed from the reference shoreline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch shoreline detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping shorelines:\n",
      "\n",
      "\r",
      "L8:   25%"
     ]
    },
    {
     "ename": "StopIteration",
     "evalue": "User cancelled checking shoreline detection",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22516/438671156.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'matplotlib'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'qt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_latlon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_proj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mShoreline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract_shorelines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msettings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpolygon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\OneDrive - Durham University\\Research_Work\\CoastWatch\\Elves\\Shoreline.py\u001b[0m in \u001b[0;36mextract_shorelines\u001b[1;34m(metadata, settings, polygon, dates)\u001b[0m\n\u001b[0;32m    221\u001b[0m                         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mioff\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# turning interactive plotting off\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m                     skip_image = show_detection(im_ms, cloud_mask, im_labels, shoreline,\n\u001b[1;32m--> 223\u001b[1;33m                                                 image_epsg, georef, settings, date, satname)\n\u001b[0m\u001b[0;32m    224\u001b[0m                     \u001b[1;31m# if the user decides to skip the image, continue and do not save the mapped shoreline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mskip_image\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive - Durham University\\Research_Work\\CoastWatch\\Elves\\Shoreline.py\u001b[0m in \u001b[0;36mshow_detection\u001b[1;34m(im_ms, cloud_mask, im_labels, shoreline, image_epsg, georef, settings, date, satname)\u001b[0m\n\u001b[0;32m    936\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mkey_event\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'pressed'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'escape'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    937\u001b[0m                 \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 938\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'User cancelled checking shoreline detection'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    939\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    940\u001b[0m                 \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitforbuttonpress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mStopIteration\u001b[0m: User cancelled checking shoreline detection"
     ]
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "output, output_latlon, output_proj = Shoreline.extract_shorelines(metadata, settings, polygon, dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alternatively, load the output file if previously processed\n",
    "filepath = os.path.join(inputs['filepath'], sitename)\n",
    "with open(os.path.join(filepath, sitename + '_output' + '.pkl'), 'rb') as f:\n",
    "    output = pickle.load(f)\n",
    "with open(os.path.join(filepath, sitename + '_output_latlon' + '.pkl'), 'rb') as f:\n",
    "    output_latlon = pickle.load(f) \n",
    "with open(os.path.join(filepath, sitename + '_output_proj' + '.pkl'), 'rb') as f:\n",
    "    output_proj = pickle.load(f) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then remove duplicates and images with inaccurate georeferencing (threhsold at 10m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output = Toolbox.remove_duplicates(output) # removes duplicates (images taken on the same date by the same satellite)\n",
    "output_latlon = Toolbox.remove_duplicates(output_latlon)\n",
    "output_proj = Toolbox.remove_duplicates(output_proj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FN THAT REMOVES BY ACTIVE CHOICE GOES HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For use in GIS applications, you can save the mapped shorelines as a GEOJSON layer which can be easily imported into QGIS for example. You can choose to save the shorelines as a collection of lines or points (sometimes the lines are crossing over so better to use points)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Visual Display of Shorelines (will tank PC if you've produced too many lines)\n",
    "\n",
    "#Creates map object centred at ROI + adds compiled satellite image as base-layer\n",
    "Map = geemap.Map(center=[polygon[0][0][1],polygon[0][0][0]],zoom=12)\n",
    "Map.add_basemap('HYBRID')\n",
    "\n",
    "#Generates colours for lines to be drawn in. Check out https://seaborn.pydata.org/tutorial/color_palettes.html for colour options...\n",
    "palette = sns.color_palette(\"bright\", len(output['shorelines']))\n",
    "palette = palette.as_hex()\n",
    "\n",
    "#Choose 'points' or 'lines' for the layer geometry\n",
    "geomtype = 'points'\n",
    "\n",
    "for i in range(len(output['shorelines'])-82):    \n",
    "    shore = dict([])\n",
    "    shore = {'dates':[output_latlon['dates'][i]], 'shorelines':[output_latlon['shorelines'][i]], 'filename':[output_latlon['filename'][i]], 'cloud_cover':[output_latlon['cloud_cover'][i]], 'geoaccuracy':[output_latlon['geoaccuracy'][i]], 'idx':[output_latlon['idx'][i]], 'Otsu_threshold':[output_latlon['Otsu_threshold'][i]], 'satname':[output_latlon['satname'][i]]}\n",
    "    \n",
    "    if len(shore['shorelines'][0])==0:\n",
    "        continue\n",
    "    \n",
    "    gdf = Toolbox.output_to_gdf(shore, geomtype)\n",
    "    Line = geemap.geopandas_to_ee(gdf, geodesic=True)\n",
    "\n",
    "    Map.addLayer(Line,{'color': str(palette[i])},'coast'+str(i))\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saves the shorelines as individual shape-files locally under /Shorelines.\n",
    "\n",
    "#Choose 'points' or 'lines' for the layer geometry\n",
    "geomtype = 'lines'\n",
    "\n",
    "for i in range(len(output['shorelines'])):\n",
    "    filename = \"Shorelines/\" + sitename + '_' + str(output['dates'][i])\n",
    "    \n",
    "    shore = dict([])\n",
    "    shore = {'dates':[output_latlon['dates'][i]], 'shorelines':[output_latlon['shorelines'][i]], 'filename':[output_latlon['filename'][i]], 'cloud_cover':[output_latlon['cloud_cover'][i]], 'geoaccuracy':[output_latlon['geoaccuracy'][i]], 'idx':[output_latlon['idx'][i]], 'MNDWI_threshold':[output_latlon['MNDWI_threshold'][i]], 'satname':[output_latlon['satname'][i]]}\n",
    "    \n",
    "    gdf = Toolbox.output_to_gdf(shore, geomtype)\n",
    "    \n",
    "    gdf.to_file(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saves the shorelines as individual shape-files locally under /Shorelines.\n",
    "direc = os.path.join(filepath, '/Shorelines')\n",
    "geomtype = 'lines'\n",
    "name_prefix = 'Data/' + sitename + '/Shorelines'\n",
    "\n",
    "if os.path.isdir(direc) is False:\n",
    "    os.mkdir(direc)\n",
    "\n",
    "Toolbox.save_shapefiles(output_latlon, geomtype, name_prefix, sitename)\n",
    "\n",
    "ref_line = np.delete(settings['reference_shoreline'],2,1)\n",
    "ref = {'dates':['3000-12-30'], 'shorelines':[ref_line], 'filename':[0], 'cloud_cover':[0], 'geoaccuracy':[0], 'idx':[0], 'Otsu_threshold':[0], 'satname':[0]}\n",
    "    \n",
    "Toolbox.save_shapefiles(ref, geomtype, name_prefix, sitename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Produces Transects and Coast shape-files for each processed shoreline\n",
    "\n",
    "SmoothingWindowSize = 21\n",
    "NoSmooths = 100\n",
    "TransectSpacing = 10\n",
    "DistanceInland = 350\n",
    "DistanceOffshore = 350\n",
    "BasePath = 'data/' + sitename + '/Shorelines'\n",
    "\n",
    "Transects.produce_transects(SmoothingWindowSize, NoSmooths, TransectSpacing, DistanceInland, DistanceOffshore, image_epsg, sitename, BasePath + '/' + sitename + '_referenceLine')\n",
    "\n",
    "#(Optional) Produces transects for all produced lines\n",
    "#Transects.produce_transects_all(SmoothingWindowSize, NoSmooths, TransectSpacing, DistanceInland, DistanceOffshore, projection_epsg, BasePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defines all transects in a library.\n",
    "\n",
    "TransectSpec =  '/' + sitename + '_referenceLine/Transect.shp'\n",
    "geo = gpd.read_file(BasePath+TransectSpec)\n",
    "\n",
    "transect_latlon, transect_proj = Transects.stuffIntoLibrary(geo, image_epsg, projection_epsg, filepath, sitename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Or just load them if already produced\n",
    "with open(os.path.join(filepath, sitename + '_transect_proj' + '.pkl'), 'rb') as f:\n",
    "    transects_proj = pickle.load(f)\n",
    "with open(os.path.join(filepath, sitename + '_transect_latlon' + '.pkl'), 'rb') as f:\n",
    "    transects_latlon = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings['along_dist'] = 50\n",
    "cross_distance = Transects.compute_intersection(output_proj, transects_proj, settings, 'shoreline_') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Or just load it if it already exists :)\n",
    "\n",
    "cross_distance = dict([])\n",
    "\n",
    "with open('Data/'+sitename+'/shoreline_transect_time_series.csv', newline='') as csvfile:\n",
    "    spamreader = csv.DictReader(csvfile, delimiter=',', quotechar='|')\n",
    "    for lines in spamreader:\n",
    "        for i in range(len(lines)-2):\n",
    "            cross_distance['Transect_'+str(i+1)] = []\n",
    "\n",
    "with open('Data/'+sitename+'/shoreline_transect_time_series.csv', newline='') as csvfile:\n",
    "    spamreader = csv.DictReader(csvfile, delimiter=',', quotechar='|')\n",
    "    for lines in spamreader:\n",
    "        for i in range(len(lines)-2):\n",
    "            transect_name = 'Transect Transect_' + str(i+1)\n",
    "            try:\n",
    "                cross_distance['Transect_'+str(i+1)].append(float(lines[transect_name]))\n",
    "            except:\n",
    "                cross_distance['Transect_'+str(i+1)].append(np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple plot of the mapped shorelines. The coordinates are stored in the output dictionnary together with the exact dates in UTC time, the georeferencing accuracy and the cloud cover."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis - Shoreline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Displays produced lines/transects\n",
    "\n",
    "fig = plt.figure(figsize=[15,8], tight_layout=True)\n",
    "plt.axis('equal')\n",
    "plt.xlabel('Eastings')\n",
    "plt.ylabel('Northings')\n",
    "#plt.xlim(509000,513000)\n",
    "#plt.ylim(6244400,6247250)\n",
    "plt.grid(linestyle=':', color='0.5')\n",
    "for i in range(len(output_proj['shorelines'])):\n",
    "    sl = output_proj['shorelines'][i]\n",
    "    date = output_proj['dates'][i]\n",
    "    plt.plot(sl[:,0], sl[:,1], '.')#, label=date.strptime('%d-%m-%Y'))\n",
    " \n",
    "for i,key in enumerate(list(transect_proj.keys())):\n",
    "    plt.plot(transect_proj[key][0,0],transect_proj[key][0,1], 'bo', ms=5)\n",
    "    plt.plot(transect_proj[key][:,0],transect_proj[key][:,1],'k-',lw=1)\n",
    "    #plt.text(transects_proj[key][0,0]-100, transects_proj[key][0,1]+100, key, va='center', ha='right', bbox=dict(boxstyle=\"square\", ec='k',fc='w'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Displays the transects\n",
    "\n",
    "for i,key in enumerate(list(transect_proj.keys())):\n",
    "    plt.plot(transect_proj[key][0,0],transect_proj[key][0,1], 'bo', ms=5)\n",
    "    plt.plot(transect_proj[key][:,0],transect_proj[key][:,1],'k-',lw=1)\n",
    "    #plt.text(transects_proj[key][0,0]-100, transects_proj[key][0,1]+100, key, va='center', ha='right', bbox=dict(boxstyle=\"square\", ec='k',fc='w'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Displays the lines\n",
    "\n",
    "fig = plt.figure(figsize=[15,8])\n",
    "plt.axis('equal')\n",
    "plt.xlabel('Eastings')\n",
    "plt.ylabel('Northings')\n",
    "plt.grid(linestyle=':', color='0.5')\n",
    "for i in range(len(output_proj['shorelines'])):\n",
    "    sl = output_proj['shorelines'][i]\n",
    "    date = output_proj['dates'][i]\n",
    "    plt.plot(sl[:,0], sl[:,1], '.')#, label=date.strftime('%d-%m-%Y'))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross-distance plots for ALL transects (do not bother if you are considering a LOT of transects)\n",
    "\n",
    "fig = plt.figure(figsize=[15,12], tight_layout=True)\n",
    "gs = gridspec.GridSpec(len(cross_distance),2, wspace=0.035, width_ratios=[3,1])\n",
    "gs.update(left=0.05, right=0.95, bottom=0.05, top=0.95, hspace=0.2)\n",
    "for i,key in enumerate(cross_distance.keys()):\n",
    "    if np.all(np.isnan(cross_distance[key])):\n",
    "        continue\n",
    "    ax = fig.add_subplot(gs[i,0])\n",
    "    ax.grid(linestyle=':', color='0.5')\n",
    "    ax.set_ylim([-100,110])\n",
    "    ax.plot(output['dates'], cross_distance[key]- np.nanmedian(cross_distance[key]), '-o', ms=6, mfc='w')\n",
    "    #ax.set_ylabel('distance [m]', fontsize=12)\n",
    "    ax.text(0.5,0.95, key, bbox=dict(boxstyle=\"square\", ec='k',fc='w'), ha='center',va='top', transform=ax.transAxes, fontsize=14)\n",
    "    if i!= len(cross_distance.keys())-1:\n",
    "        ax.set_xticklabels('')\n",
    "    ax = fig.add_subplot(gs[i,1])\n",
    "    #ax.set_xlim([-50,50])\n",
    "    ax.set_xlim([0,0.015])\n",
    "    sns.distplot(cross_distance[key]- np.nanmedian(cross_distance[key]), bins=10, color=\"b\", ax=ax, vertical=True)\n",
    "    ax.set_yticklabels('')\n",
    "    if i!= len(cross_distance.keys())-1:\n",
    "        ax.set_xticklabels('')\n",
    "fig.text(0.01, 0.5, 'Cross-Shore Distance / m', va='center', rotation='vertical', fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transect_range = [[0, 50],[51,110],[111,180],[181,240],[241,len(output['dates'])-1]]\n",
    "#transect_colour = sns.color_palette(\"bright\", len(transect_range))\n",
    "colours = ['#ff0000','#0084ff','#ff00f7','#00fa0c', '#ffb300', '#00ffcc','#7b00ff']\n",
    "transect_colour = colours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=[15,8], tight_layout=True)\n",
    "plt.axis('equal')\n",
    "plt.xlabel('Eastings')\n",
    "plt.ylabel('Northings')\n",
    "#plt.xlim(509000,513000)\n",
    "#plt.ylim(6244400,6247250)\n",
    "plt.grid(linestyle=':', color='0.5')\n",
    "for i in range(len(output_proj['shorelines'])):\n",
    "    sl = output_proj['shorelines'][i]\n",
    "    date = output_proj['dates'][i]\n",
    "    plt.plot(sl[:,0], sl[:,1], '.')#, label=date.strptime('%d-%m-%Y'))\n",
    "\n",
    "if transect_range == 'full':\n",
    "    transect_range = [[0,len(transect_proj.keys())]]   \n",
    "\n",
    "for i,key in enumerate(list(transect_proj.keys())):\n",
    "    for j in range(len(transect_range)):\n",
    "        if transect_range[j][0] <= i <= transect_range[j][1]:\n",
    "            plt.plot(transect_proj[key][0,0],transect_proj[key][0,1], 'bo', ms=5,color=transect_colour[j])\n",
    "            plt.plot(transect_proj[key][:,0],transect_proj[key][:,1],'k-',lw=1,color=transect_colour[j])\n",
    "    #plt.text(transects_proj[key][0,0]-100, transects_proj[key][0,1]+100, key, va='center', ha='right', bbox=dict(boxstyle=\"square\", ec='k',fc='w'))\n",
    "\n",
    "plt.savefig('Data/' + sitename + '/jpg_files/transectsFullShore', bbox_inches='tight')\n",
    "  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Year by Year\n",
    "\n",
    "from matplotlib import rcParams\n",
    "rcParams.update({'figure.autolayout': True})\n",
    "\n",
    "fig, axs = plt.subplots(len(transect_range),sharex=True,figsize=(10, 12))\n",
    "fig.text(0.005, 0.5, \"Average Yearly Vegetation Cross-Edge Distance / m\", va='center', rotation='vertical', fontsize=12)\n",
    "\n",
    "for i in range(len(transect_range)):\n",
    "    axs[i].set_title(\"Transects:\"+str(transect_range[i][0])+\"-\"+str(transect_range[i][1]),backgroundcolor=transect_colour[i],color='white')\n",
    "    if i != len(transect_range)-1:\n",
    "        axs[i].xaxis.set_visible(False)\n",
    "    if i == len(transect_range)-1:\n",
    "        axs[i].set_xlabel(\"Year\", fontsize=12)\n",
    "    for j in range(transect_range[i][0],transect_range[i][1]):\n",
    "        KEY = 'Transect_'+str(j+1)\n",
    "        try:\n",
    "            a, b, c, d, e = Toolbox.Separate_TimeSeries_year(cross_distance, output_proj, KEY)\n",
    "            NaN_mask = np.isfinite(e)\n",
    "            axs[i].plot(np.array(d)[NaN_mask],np.array(e)[NaN_mask])\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "plt.savefig('Data/' + sitename + '/jpg_files/avgYearlyVegPositionShore', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Good at looking at seasonal patterns. Takes a while.\n",
    "\n",
    "#plt.figure(figsize=[15,12])\n",
    "\n",
    "months = [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"June\", \"July\", \"Aug\", \"Sept\", \"Oct\", \"Nov\", \"Dec\"]\n",
    "Month_dict = {\"Jan\":[], \"Feb\":[], \"Mar\":[], \"Apr\":[], \"May\":[], \"June\":[], \"July\":[], \"Aug\":[], \"Sept\":[], \"Oct\":[], \"Nov\":[], \"Dec\":[]}\n",
    "\n",
    "Total_Month_Arr = []\n",
    "test1 = []\n",
    "test2 = []\n",
    "\n",
    "fig, axs = plt.subplots(len(transect_range),sharex=True,figsize=(10, 12))\n",
    "\n",
    "for l in range(len(transect_range)):\n",
    "\n",
    "    for i in range(transect_range[l][0],transect_range[l][1]):\n",
    "        KEY = 'Transect_'+str(i+1)\n",
    "        try:\n",
    "            a, b, c, d, e = Toolbox.Separate_TimeSeries_month(cross_distance, output_proj,KEY)\n",
    "\n",
    "            zipped_lists = zip(d,e)\n",
    "            s = sorted(zipped_lists)\n",
    "            tuples = zip(s)\n",
    "\n",
    "            new_d = []\n",
    "            new_e = []\n",
    "\n",
    "            sortedList = [list(tuple) for tuple in  tuples]\n",
    "\n",
    "            for v in range(len(sortedList)):\n",
    "                new_d.append(sortedList[v][0][0])\n",
    "                new_e.append(sortedList[v][0][1])\n",
    "\n",
    "            month_arr = []\n",
    "            for j in range(len(d)):\n",
    "                a = datetime.strptime(str(new_d[j]),'%m')\n",
    "                month_arr.append(a.strftime('%b'))\n",
    "\n",
    "            axs[l].scatter(month_arr,new_e,label=KEY)\n",
    "            test1.append(new_d)\n",
    "            test2.append(new_e)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    avg = []\n",
    "    st_err = []\n",
    "    Total_organised = []\n",
    "    temp = []\n",
    "\n",
    "    for k in range(len(test2[0])):\n",
    "        for h in range(len(test2)):\n",
    "            temp.append(test2[h][k])\n",
    "        Total_organised.append(temp)\n",
    "        avg.append(np.nanmean(temp))\n",
    "        st_err.append(np.nanstd(temp)/(len(temp)**0.5))\n",
    "        temp = []\n",
    "    \n",
    "    Total_Month_Arr.append(Total_organised)\n",
    "    \n",
    "    #plt.errorbar(month_arr,avg, yerr=st_err, color='k')\n",
    "    axs[l].scatter(month_arr,avg, color='k', s=50, marker='x')\n",
    "\n",
    "    #plt.legend()\n",
    "    axs[l].set_title(\"Transects:\"+str(transect_range[l][0])+\"-\"+str(transect_range[l][1]),backgroundcolor=transect_colour[l],color='white')\n",
    "\n",
    "fig.text(0.01,0.5,\"Averaged Monthly Vegetation Cross-Edge Distance / m\", va='center', rotation='vertical')\n",
    "plt.xlabel(\"Month\")\n",
    "\n",
    "plt.savefig('Data/' + sitename + '/jpg_files/monthScatterShore', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(len(transect_range),sharex=True,figsize=(10, 12))\n",
    "\n",
    "for j in range(len(Total_Month_Arr)):\n",
    "    \n",
    "    axs[j].set_title(\"Transects:\"+str(transect_range[j][0])+\"-\"+str(transect_range[j][1]),backgroundcolor=transect_colour[j],color='white')\n",
    "    axs[j].boxplot(Total_Month_Arr[j],notch=True, flierprops = dict(marker='o', markersize=8, linestyle='none', markeredgecolor='r'))\n",
    "\n",
    "fig.text(0.01,0.5,\"Averaged Monthly Vegetation Cross-Edge Distance / m\", va='center', rotation='vertical')\n",
    "plt.xticks(new_d, month_arr)\n",
    "\n",
    "plt.savefig('Data/' + sitename + '/jpg_files/monthBoxShore', bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjacent_values(vals, q1, q3):\n",
    "    upper_adjacent_value = q3 + (q3 - q1) * 1.5\n",
    "    upper_adjacent_value = np.clip(upper_adjacent_value, q3, vals[-1])\n",
    "\n",
    "    lower_adjacent_value = q1 - (q3 - q1) * 1.5\n",
    "    lower_adjacent_value = np.clip(lower_adjacent_value, vals[0], q1)\n",
    "    return lower_adjacent_value, upper_adjacent_value\n",
    "\n",
    "\n",
    "def set_axis_style(ax, labels):\n",
    "    ax.xaxis.set_tick_params(direction='out')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.set_xticks(np.arange(1, len(labels) + 1))\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.set_xlim(0.25, len(labels) + 0.75)\n",
    "    #ax.set_xlabel('Sample name')\n",
    "\n",
    "fig, axs = plt.subplots(len(transect_range),sharex=True,figsize=(10, 12))\n",
    "\n",
    "for j in range(len(Total_Month_Arr)):\n",
    "    \n",
    "    axs[j].set_title(\"Transects:\"+str(transect_range[j][0])+\"-\"+str(transect_range[j][1]),backgroundcolor=transect_colour[j],color='white')\n",
    "    parts = axs[j].violinplot(Total_Month_Arr[j], showmeans=False, showmedians=False, showextrema=False)\n",
    "\n",
    "    for pc in parts['bodies']:\n",
    "        pc.set_facecolor(transect_colour[j])\n",
    "        pc.set_edgecolor('black')\n",
    "        pc.set_alpha(0.7)\n",
    "\n",
    "    quartile1, medians, quartile3 = np.percentile(Total_Month_Arr[j], [25, 50, 75], axis=1)\n",
    "    whiskers = np.array([\n",
    "        adjacent_values(sorted_array, q1, q3)\n",
    "        for sorted_array, q1, q3 in zip(Total_Month_Arr[j], quartile1, quartile3)])\n",
    "    whiskers_min, whiskers_max = whiskers[:, 0], whiskers[:, 1]\n",
    "\n",
    "    inds = np.arange(1, len(medians) + 1)\n",
    "    axs[j].scatter(inds, medians, marker='o', color='white', s=30, zorder=3)\n",
    "    axs[j].vlines(inds, quartile1, quartile3, color='k', linestyle='-', lw=5)\n",
    "    axs[j].vlines(inds, whiskers_min, whiskers_max, color='k', linestyle='-', lw=1)\n",
    "    \n",
    "    if j == len(Total_Month_Arr):\n",
    "        set_axis_style(axs[j], month_arr)\n",
    "\n",
    "fig.text(0.005,0.5,\"Averaged Monthly Vegetation Cross-Edge Distance / m\", va='center', rotation='vertical')\n",
    "plt.xticks(new_d, month_arr)\n",
    "\n",
    "plt.savefig('Data/' + sitename + '/jpg_files/monthViolinShore', bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rows = []\n",
    "\n",
    "with open('Data/'+sitename+'/vegetation_transect_time_series.csv', newline='') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "    for row in spamreader:\n",
    "        Rows.append(row[2:])\n",
    "\n",
    "cross_distance_condensed, standard_err_condensed, transect_condensed, Dates = Transects.transect_compiler(Rows, transect_proj, 100, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=[15,12], tight_layout=True)\n",
    "gs = gridspec.GridSpec(len(cross_distance_condensed),2, wspace=0.035, width_ratios=[4,1])\n",
    "gs.update(left=0.05, right=0.95, bottom=0.05, top=0.95, hspace=0.05)\n",
    "\n",
    "x = np.arange(datetime(1984,1,1), datetime(2022,1,1), timedelta(days=100)).astype(str)\n",
    "y = [0]*139\n",
    "\n",
    "for i,key in enumerate(cross_distance_condensed.keys()):\n",
    "    \n",
    "    if np.all(np.isnan(cross_distance_condensed[key])):\n",
    "        continue\n",
    "        \n",
    "    ax = fig.add_subplot(gs[i,0])\n",
    "    ax.grid(linestyle=':', color='0.5')\n",
    "    ax.set_ylim([min(cross_distance_condensed[key]- np.nanmedian(cross_distance_condensed[key]))-5,max(cross_distance_condensed[key]- np.nanmedian(cross_distance_condensed[key]))+5])\n",
    "    dates = matplotlib.dates.date2num(Dates[key])\n",
    "    ax.errorbar(dates, cross_distance_condensed[key]- np.nanmedian(cross_distance_condensed[key]), yerr = standard_err_condensed[key],fmt='-o',ecolor= 'k', color= colours[i], ms=6, mfc='w')\n",
    "    #ax.plot_date(Dates[key], cross_distance_condensed[key]- np.nanmedian(cross_distance_condensed[key]), xdate=True,fmt='-o', color= colours[i], ms=6, mfc='w')\n",
    "    #ax.fill_between(Dates[key], 0, cross_distance_condensed[key]- np.nanmedian(cross_distance_condensed[key]),alpha=0.5,color=colours[i])\n",
    "    \n",
    "    #ax.plot(x,y,color='k')\n",
    "    \n",
    "    #ax.text(0.5,0.95, key, bbox=dict(boxstyle=\"square\", ec='k',fc='w'), ha='center',va='top', transform=ax.transAxes, fontsize=14)\n",
    "    #ax.set_xlim(min(Dates[key]),max(Dates[key]))\n",
    "    #ax.set_xticklabels(linspace_datetime64(np.datetime64(min(Dates[key])),np.datetime64(max(Dates[key])), 7))#,rotation=45)\n",
    "    #ax.tick_params(axis='both', which='minor', labelsize=12)\n",
    "    #ax.grid(False,axis='x')\n",
    "    \n",
    "    ax.fill_between(dates, 0, cross_distance_condensed[key]- np.nanmedian(cross_distance_condensed[key]),alpha=0.5,color=colours[i])\n",
    "    ax.set_title(\"Transects:\"+str(transect_range[i][0])+\"-\"+str(transect_range[i][1]),backgroundcolor=transect_colour[i],color='white')\n",
    "    #ax.xaxis.set_major_locator(locator)\n",
    "    #ax.set_xticks(dates, minor=False)\n",
    "    ax.set_xticklabels(['1982','1986','1992','1998','2004','2010','2016','2020','2014','2018','2022'])\n",
    "    #ax.set_xticks(dates, minor=False)\n",
    "    #ax.set_xticklabels(Dates[key])\n",
    "    #locator=MaxNLocator(12)\n",
    "    #ax.xaxis.set_major_locator(locator)\n",
    "    if i!= len(cross_distance_condensed.keys())-1:\n",
    "        ax.set_xticklabels('')\n",
    "    #ax.set_xticks(Dates[key])\n",
    "\n",
    "    ax = fig.add_subplot(gs[i,1])\n",
    "    #ax.set_xlim([-50,50])\n",
    "    ax.set_xlim([0,0.020])\n",
    "    sns.distplot(cross_distance_condensed[key]- np.nanmedian(cross_distance_condensed[key]), bins=10, color=colours[i], ax=ax, vertical=True)\n",
    "    ax.set_yticklabels('')\n",
    "    \n",
    "    if i!= len(cross_distance_condensed.keys())-1:\n",
    "        ax.set_xticklabels('')\n",
    "        ax.set_xlabel('')\n",
    "        \n",
    "fig.text(0.01, 0.5, 'Cross Vegetation-Edge Distance / m', va='center', rotation='vertical', fontsize=13.8)\n",
    "\n",
    "plt.savefig('Data/' + sitename + '/jpg_files/crossEdgeDistancesShore', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Veg Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BasePath = 'Data/' + sitename + '/Veglines'\n",
    "\n",
    "if os.path.isdir(BasePath) is False:\n",
    "    os.mkdir(BasePath)\n",
    "\n",
    "settings = {\n",
    "    # general parameters:\n",
    "    'cloud_thresh': 0.5,        # threshold on maximum cloud cover\n",
    "    'output_epsg': projection_epsg,     # epsg code of spatial reference system desired for the output   \n",
    "    # quality control:\n",
    "    'check_detection': True,    # if True, shows each shoreline detection to the user for validation\n",
    "    'adjust_detection': False,  # if True, allows user to adjust the postion of each shoreline by changing the threhold\n",
    "    'save_figure': True,        # if True, saves a figure showing the mapped shoreline for each image\n",
    "    # [ONLY FOR ADVANCED USERS] shoreline detection parameters:\n",
    "    'min_beach_area': 50,     # minimum area (in metres^2) for an object to be labelled as a beach\n",
    "    'buffer_size': 150,         # radius (in metres) for buffer around sandy pixels considered in the shoreline detection\n",
    "    'min_length_sl': 100,       # minimum length (in metres) of shoreline perimeter to be valid\n",
    "    'cloud_mask_issue': False,  # switch this parameter to True if sand pixels are masked (in black) on many images  \n",
    "    'sand_color': 'bright',    # 'default', 'dark' (for grey/black sand beaches) or 'bright' (for white sand beaches)\n",
    "    # add the inputs defined previously\n",
    "    'inputs': inputs,\n",
    "    'projection_epsg': 27700,\n",
    "    'hausdorff_threshold':3500000000000\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Digitize a reference vegetation line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "settings['reference_shoreline'] = Image_Processing.get_reference_sl(metadata, settings, polygon, dates)\n",
    "settings['max_dist_ref'] = 100 # max distance (in meters) allowed from the reference shoreline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracts vegetation lines from all selected images. This'll take a while..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "output, output_latlon, output_proj = VegetationLine.extract_veglines(metadata, settings, polygon, dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alternatively, load the output file if previously processed\n",
    "filepath = os.path.join(inputs['filepath'], sitename)\n",
    "with open(os.path.join(filepath, sitename + '_output.pkl'), 'rb') as f:\n",
    "    output = pickle.load(f)\n",
    "with open(os.path.join(filepath, sitename + '_output_latlon.pkl'), 'rb') as f:\n",
    "    output_latlon = pickle.load(f)\n",
    "with open(os.path.join(filepath, sitename + '_output_proj.pkl'), 'rb') as f:\n",
    "    output_proj = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = Toolbox.remove_duplicates(output) # removes duplicates (images taken on the same date by the same satellite)\n",
    "output_latlon = Toolbox.remove_duplicates(output_latlon)\n",
    "output_proj = Toolbox.remove_duplicates(output_proj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FN THAT REMOVES BY ACTIVE CHOICE GOES HERE\n",
    "\n",
    "\"\"\"\n",
    "b = LineString(output['shorelines'][j])\n",
    "b\n",
    "\n",
    "from ipywidgets import Checkbox, Output\n",
    "import json\n",
    "\n",
    "with open('data.txt', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "item = Checkbox(value=data['item'], description='item')\n",
    "out = Output()\n",
    "\n",
    "@out.capture()\n",
    "def on_value_change(change):\n",
    "    key = change['owner'].description\n",
    "    value = change['new']\n",
    "    \n",
    "    print(f'Saving value: \"{{ \\'{key}\\': {value} }}\"')\n",
    "    \n",
    "    data[key] = value\n",
    "    with open('data.txt', 'w') as f:\n",
    "        json.dump(data, f)\n",
    "\n",
    "item.observe(on_value_change, names='value')\n",
    "display(item)\n",
    "display(out)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visual Display of Vegetation Lines. Will tank your PC if you've got lots of lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Creates map object centred at ROI + adds compiled satellite image as base-layer\n",
    "Map = geemap.Map(center=[polygon[0][0][1],polygon[0][0][0]],zoom=12)\n",
    "Map.add_basemap('HYBRID')\n",
    "\n",
    "#Generates colours for lines to be drawn in. Check out https://seaborn.pydata.org/tutorial/color_palettes.html for colour options...\n",
    "palette = sns.color_palette(\"bright\", len(output['shorelines']))\n",
    "palette = palette.as_hex()\n",
    "\n",
    "#Choose 'points' or 'lines' for the layer geometry\n",
    "geomtype = 'points'\n",
    "\n",
    "for i in range(len(output['shorelines'])-230):\n",
    "    shore = dict([])\n",
    "    if len(output_latlon['shorelines'][i])==0:\n",
    "        continue\n",
    "    shore = {'dates':[output_latlon['dates'][i]], 'shorelines':[output_latlon['shorelines'][i]], 'filename':[output_latlon['filename'][i]], 'cloud_cover':[output_latlon['cloud_cover'][i]], 'idx':[output_latlon['idx'][i]], 'Otsu_threshold':[output_latlon['Otsu_threshold'][i]], 'satname':[output_latlon['satname'][i]]}\n",
    "    gdf = Toolbox.output_to_gdf(shore, geomtype)\n",
    "    Line = geemap.geopandas_to_ee(gdf, geodesic=True)\n",
    "    Map.addLayer(Line,{'color': str(palette[i])},'coast'+str(i))\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saves the veglines as individual shape-files locally under /Veglines.\n",
    "direc = os.path.join(filepath, '/Veglines')\n",
    "geomtype = 'lines'\n",
    "name_prefix = 'Data/' + sitename + '/Veglines'\n",
    "\n",
    "if os.path.isdir(direc) is False:\n",
    "    os.mkdir(direc)\n",
    "\n",
    "Toolbox.save_shapefiles(output_latlon, geomtype, name_prefix, sitename)\n",
    "\n",
    "ref_line = np.delete(settings['reference_shoreline'],2,1)\n",
    "ref = {'dates':['3000-12-30'], 'shorelines':[ref_line], 'filename':[0], 'cloud_cover':[0], 'geoaccuracy':[0], 'idx':[0], 'Otsu_threshold':[0], 'satname':[0]}\n",
    "    \n",
    "Toolbox.save_shapefiles(ref, geomtype, name_prefix, sitename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Produces Transects and Coast shape-files for the reference line\n",
    "\n",
    "SmoothingWindowSize = 21\n",
    "NoSmooths = 100\n",
    "TransectSpacing = 10\n",
    "DistanceInland = 350\n",
    "DistanceOffshore = 350\n",
    "BasePath = 'Data/' + sitename + '/Veglines'\n",
    "\n",
    "Transects.produce_transects(SmoothingWindowSize, NoSmooths, TransectSpacing, DistanceInland, DistanceOffshore, image_epsg, sitename, BasePath + '/' + sitename + '_referenceLine')\n",
    "\n",
    "#(Optional) Produces transects for all produced lines\n",
    "#Transects.produce_transects_all(SmoothingWindowSize, NoSmooths, TransectSpacing, DistanceInland, DistanceOffshore, projection_epsg, BasePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Defines all transects in a library.\n",
    "\n",
    "TransectSpec =  '/' + sitename + '_referenceLine/Transect.shp'\n",
    "geo = gpd.read_file(BasePath+TransectSpec)\n",
    "\n",
    "transect_latlon, transect_proj = Transects.stuffIntoLibrary(geo, image_epsg, projection_epsg, filepath, sitename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Or just load them if already produced\n",
    "with open(os.path.join(filepath, sitename + '_transect_proj' + '.pkl'), 'rb') as f:\n",
    "    transect_proj = pickle.load(f)\n",
    "with open(os.path.join(filepath, sitename + '_transect_latlon' + '.pkl'), 'rb') as f:\n",
    "    transect_latlon = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defines the along-shore distance over which to consider vegetation line points to compute the median intersection (robust to outliers)\n",
    "settings['along_dist'] = 50\n",
    "cross_distance = Transects.compute_intersection(output_proj, transect_proj, settings, 'vegetation_') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Or just load it if it already exists :)\n",
    "\n",
    "cross_distance = dict([])\n",
    "\n",
    "with open('Data/'+sitename+'/vegetation_transect_time_series.csv', newline='') as csvfile:\n",
    "    spamreader = csv.DictReader(csvfile, delimiter=',', quotechar='|')\n",
    "    for lines in spamreader:\n",
    "        for i in range(len(lines)-2):\n",
    "            cross_distance['Transect_'+str(i+1)] = []\n",
    "\n",
    "with open('Data/'+sitename+'/vegetation_transect_time_series.csv', newline='') as csvfile:\n",
    "    spamreader = csv.DictReader(csvfile, delimiter=',', quotechar='|')\n",
    "    for lines in spamreader:\n",
    "        for i in range(len(lines)-2):\n",
    "            transect_name = 'Transect Transect_' + str(i+1)\n",
    "            try:\n",
    "                cross_distance['Transect_'+str(i+1)].append(float(lines[transect_name]))\n",
    "            except:\n",
    "                cross_distance['Transect_'+str(i+1)].append(np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis - Vegetation Edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Displays produced lines/transects\n",
    "\n",
    "fig = plt.figure(figsize=[15,8], tight_layout=True)\n",
    "plt.axis('equal')\n",
    "plt.xlabel('Eastings')\n",
    "plt.ylabel('Northings')\n",
    "#plt.xlim(509000,513000)\n",
    "#plt.ylim(6244400,6247250)\n",
    "plt.grid(linestyle=':', color='0.5')\n",
    "for i in range(len(output_proj['shorelines'])):\n",
    "    sl = output_proj['shorelines'][i]\n",
    "    date = output_proj['dates'][i]\n",
    "    plt.plot(sl[:,0], sl[:,1], '.')#, label=date.strptime('%d-%m-%Y'))\n",
    " \n",
    "for i,key in enumerate(list(transect_proj.keys())):\n",
    "    plt.plot(transect_proj[key][0,0],transect_proj[key][0,1], 'bo', ms=5)\n",
    "    plt.plot(transect_proj[key][:,0],transect_proj[key][:,1],'k-',lw=1)\n",
    "    #plt.text(transects_proj[key][0,0]-100, transects_proj[key][0,1]+100, key, va='center', ha='right', bbox=dict(boxstyle=\"square\", ec='k',fc='w'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Displays the transects\n",
    "\n",
    "for i,key in enumerate(list(transect_proj.keys())):\n",
    "    plt.plot(transect_proj[key][0,0],transect_proj[key][0,1], 'bo', ms=5)\n",
    "    plt.plot(transect_proj[key][:,0],transect_proj[key][:,1],'k-',lw=1)\n",
    "    #plt.text(transects_proj[key][0,0]-100, transects_proj[key][0,1]+100, key, va='center', ha='right', bbox=dict(boxstyle=\"square\", ec='k',fc='w'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Displays the lines\n",
    "\n",
    "fig = plt.figure(figsize=[15,8])\n",
    "plt.axis('equal')\n",
    "plt.xlabel('Eastings')\n",
    "plt.ylabel('Northings')\n",
    "plt.grid(linestyle=':', color='0.5')\n",
    "for i in range(len(output_proj['shorelines'])):\n",
    "    sl = output_proj['shorelines'][i]\n",
    "    date = output_proj['dates'][i]\n",
    "    plt.plot(sl[:,0], sl[:,1], '.')#, label=date.strftime('%d-%m-%Y'))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Cross-distance plots for ALL transects (do not bother if you are considering a LOT of transects)\n",
    "\n",
    "fig = plt.figure(figsize=[15,12], tight_layout=True)\n",
    "gs = gridspec.GridSpec(len(cross_distance),2, wspace=0.035, width_ratios=[3,1])\n",
    "gs.update(left=0.05, right=0.95, bottom=0.05, top=0.95, hspace=0.2)\n",
    "for i,key in enumerate(cross_distance.keys()):\n",
    "    if np.all(np.isnan(cross_distance[key])):\n",
    "        continue\n",
    "    ax = fig.add_subplot(gs[i,0])\n",
    "    ax.grid(linestyle=':', color='0.5')\n",
    "    ax.set_ylim([-100,110])\n",
    "    ax.plot(output['dates'], cross_distance[key]- np.nanmedian(cross_distance[key]), '-o', ms=6, mfc='w')\n",
    "    #ax.set_ylabel('distance [m]', fontsize=12)\n",
    "    ax.text(0.5,0.95, key, bbox=dict(boxstyle=\"square\", ec='k',fc='w'), ha='center',va='top', transform=ax.transAxes, fontsize=14)\n",
    "    if i!= len(cross_distance.keys())-1:\n",
    "        ax.set_xticklabels('')\n",
    "    ax = fig.add_subplot(gs[i,1])\n",
    "    #ax.set_xlim([-50,50])\n",
    "    ax.set_xlim([0,0.015])\n",
    "    sns.distplot(cross_distance[key]- np.nanmedian(cross_distance[key]), bins=10, color=\"b\", ax=ax, vertical=True)\n",
    "    ax.set_yticklabels('')\n",
    "    if i!= len(cross_distance.keys())-1:\n",
    "        ax.set_xticklabels('')\n",
    "fig.text(0.01, 0.5, 'Cross-Shore Distance / m', va='center', rotation='vertical', fontsize=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In this cell, you can iterate on transect range (we will use these ranges to analyse specific regions of the edge)\n",
    "\n",
    "transect_range = [[0, 50],[51,110],[111,180],[181,240],[241,len(output['dates'])-1]] #enter 'full' to select all transects in one\n",
    "#transect_colour = sns.color_palette(\"bright\", len(transect_range))\n",
    "transect_colour = ['#ff0000','#0084ff','#ff00f7','#00fa0c', '#ffb300', '#00ffcc','#7b00ff']\n",
    "\n",
    "fig = plt.figure(figsize=[15,8], tight_layout=True)\n",
    "plt.axis('equal')\n",
    "plt.xlabel('Eastings')\n",
    "plt.ylabel('Northings')\n",
    "#plt.xlim(509000,513000)\n",
    "#plt.ylim(6244400,6247250)\n",
    "plt.grid(linestyle=':', color='0.5')\n",
    "for i in range(len(output_proj['shorelines'])):\n",
    "    sl = output_proj['shorelines'][i]\n",
    "    date = output_proj['dates'][i]\n",
    "    plt.plot(sl[:,0], sl[:,1], '.')#, label=date.strptime('%d-%m-%Y'))\n",
    "\n",
    "if transect_range == 'full':\n",
    "    transect_range = [[0,len(transect_proj.keys())]]   \n",
    "\n",
    "for i,key in enumerate(list(transect_proj.keys())):\n",
    "    for j in range(len(transect_range)):\n",
    "        if transect_range[j][0] <= i <= transect_range[j][1]:\n",
    "            plt.plot(transect_proj[key][0,0],transect_proj[key][0,1], 'bo', ms=5,color=transect_colour[j])\n",
    "            plt.plot(transect_proj[key][:,0],transect_proj[key][:,1],'k-',lw=1,color=transect_colour[j])\n",
    "    #plt.text(transects_proj[key][0,0]-100, transects_proj[key][0,1]+100, key, va='center', ha='right', bbox=dict(boxstyle=\"square\", ec='k',fc='w'))\n",
    "\n",
    "plt.savefig('Data/' + sitename + '/jpg_files/transectsFull', bbox_inches='tight')\n",
    "  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Year by Year\n",
    "\n",
    "from matplotlib import rcParams\n",
    "rcParams.update({'figure.autolayout': True})\n",
    "\n",
    "fig, axs = plt.subplots(len(transect_range),sharex=True,figsize=(10, 12))\n",
    "fig.text(0.005, 0.5, \"Average Yearly Vegetation Cross-Edge Distance / m\", va='center', rotation='vertical', fontsize=12)\n",
    "\n",
    "for i in range(len(transect_range)):\n",
    "    axs[i].set_title(\"Transects:\"+str(transect_range[i][0])+\"-\"+str(transect_range[i][1]),backgroundcolor=transect_colour[i],color='white')\n",
    "    if i != len(transect_range)-1:\n",
    "        axs[i].xaxis.set_visible(False)\n",
    "    if i == len(transect_range)-1:\n",
    "        axs[i].set_xlabel(\"Year\", fontsize=12)\n",
    "    for j in range(transect_range[i][0],transect_range[i][1]):\n",
    "        KEY = 'Transect_'+str(j+1)\n",
    "        try:\n",
    "            a, b, c, d, e = Toolbox.Separate_TimeSeries_year(cross_distance, output_proj, KEY)\n",
    "            NaN_mask = np.isfinite(e)\n",
    "            axs[i].plot(np.array(d)[NaN_mask],np.array(e)[NaN_mask])\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "plt.savefig('Data/' + sitename + '/jpg_files/avgYearlyVegPosition', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Good at looking at seasonal patterns. Takes a while.\n",
    "\n",
    "#plt.figure(figsize=[15,12])\n",
    "\n",
    "months = [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"June\", \"July\", \"Aug\", \"Sept\", \"Oct\", \"Nov\", \"Dec\"]\n",
    "Month_dict = {\"Jan\":[], \"Feb\":[], \"Mar\":[], \"Apr\":[], \"May\":[], \"June\":[], \"July\":[], \"Aug\":[], \"Sept\":[], \"Oct\":[], \"Nov\":[], \"Dec\":[]}\n",
    "\n",
    "Total_Month_Arr = []\n",
    "test1 = []\n",
    "test2 = []\n",
    "\n",
    "fig, axs = plt.subplots(len(transect_range),sharex=True,figsize=(10, 12))\n",
    "\n",
    "for l in range(len(transect_range)):\n",
    "\n",
    "    for i in range(transect_range[l][0],transect_range[l][1]):\n",
    "        KEY = 'Transect_'+str(i+1)\n",
    "        try:\n",
    "            a, b, c, d, e = Toolbox.Separate_TimeSeries_month(cross_distance, output_proj,KEY)\n",
    "\n",
    "            zipped_lists = zip(d,e)\n",
    "            s = sorted(zipped_lists)\n",
    "            tuples = zip(s)\n",
    "\n",
    "            new_d = []\n",
    "            new_e = []\n",
    "\n",
    "            sortedList = [list(tuple) for tuple in  tuples]\n",
    "\n",
    "            for v in range(len(sortedList)):\n",
    "                new_d.append(sortedList[v][0][0])\n",
    "                new_e.append(sortedList[v][0][1])\n",
    "\n",
    "            month_arr = []\n",
    "            for j in range(len(d)):\n",
    "                a = datetime.strptime(str(new_d[j]),'%m')\n",
    "                month_arr.append(a.strftime('%b'))\n",
    "\n",
    "            axs[l].scatter(month_arr,new_e,label=KEY)\n",
    "            test1.append(new_d)\n",
    "            test2.append(new_e)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    avg = []\n",
    "    st_err = []\n",
    "    Total_organised = []\n",
    "    temp = []\n",
    "\n",
    "    for k in range(len(test2[0])):\n",
    "        for h in range(len(test2)):\n",
    "            temp.append(test2[h][k])\n",
    "        Total_organised.append(temp)\n",
    "        avg.append(np.nanmean(temp))\n",
    "        st_err.append(np.nanstd(temp)/(len(temp)**0.5))\n",
    "        temp = []\n",
    "    \n",
    "    Total_Month_Arr.append(Total_organised)\n",
    "    \n",
    "    #plt.errorbar(month_arr,avg, yerr=st_err, color='k')\n",
    "    axs[l].scatter(month_arr,avg, color='k', s=50, marker='x')\n",
    "\n",
    "    #plt.legend()\n",
    "    axs[l].set_title(\"Transects:\"+str(transect_range[l][0])+\"-\"+str(transect_range[l][1]),backgroundcolor=transect_colour[l],color='white')\n",
    "\n",
    "fig.text(0.01,0.5,\"Averaged Monthly Vegetation Cross-Edge Distance / m\", va='center', rotation='vertical')\n",
    "plt.xlabel(\"Month\")\n",
    "\n",
    "plt.savefig('Data/' + sitename + '/jpg_files/monthScatter', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(len(transect_range),sharex=True,figsize=(10, 12))\n",
    "\n",
    "for j in range(len(Total_Month_Arr)):\n",
    "    \n",
    "    axs[j].set_title(\"Transects:\"+str(transect_range[j][0])+\"-\"+str(transect_range[j][1]),backgroundcolor=transect_colour[j],color='white')\n",
    "    axs[j].boxplot(Total_Month_Arr[j],notch=True, flierprops = dict(marker='o', markersize=8, linestyle='none', markeredgecolor='r'))\n",
    "\n",
    "fig.text(0.01,0.5,\"Averaged Monthly Vegetation Cross-Edge Distance / m\", va='center', rotation='vertical')\n",
    "plt.xticks(new_d, month_arr)\n",
    "\n",
    "plt.savefig('Data/' + sitename + '/jpg_files/monthBox', bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjacent_values(vals, q1, q3):\n",
    "    upper_adjacent_value = q3 + (q3 - q1) * 1.5\n",
    "    upper_adjacent_value = np.clip(upper_adjacent_value, q3, vals[-1])\n",
    "\n",
    "    lower_adjacent_value = q1 - (q3 - q1) * 1.5\n",
    "    lower_adjacent_value = np.clip(lower_adjacent_value, vals[0], q1)\n",
    "    return lower_adjacent_value, upper_adjacent_value\n",
    "\n",
    "\n",
    "def set_axis_style(ax, labels):\n",
    "    ax.xaxis.set_tick_params(direction='out')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.set_xticks(np.arange(1, len(labels) + 1))\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.set_xlim(0.25, len(labels) + 0.75)\n",
    "    #ax.set_xlabel('Sample name')\n",
    "\n",
    "fig, axs = plt.subplots(len(transect_range),sharex=True,figsize=(10, 12))\n",
    "\n",
    "for j in range(len(Total_Month_Arr)):\n",
    "    \n",
    "    axs[j].set_title(\"Transects:\"+str(transect_range[j][0])+\"-\"+str(transect_range[j][1]),backgroundcolor=transect_colour[j],color='white')\n",
    "    parts = axs[j].violinplot(Total_Month_Arr[j], showmeans=False, showmedians=False, showextrema=False)\n",
    "\n",
    "    for pc in parts['bodies']:\n",
    "        pc.set_facecolor(transect_colour[j])\n",
    "        pc.set_edgecolor('black')\n",
    "        pc.set_alpha(0.7)\n",
    "\n",
    "    quartile1, medians, quartile3 = np.percentile(Total_Month_Arr[j], [25, 50, 75], axis=1)\n",
    "    whiskers = np.array([\n",
    "        adjacent_values(sorted_array, q1, q3)\n",
    "        for sorted_array, q1, q3 in zip(Total_Month_Arr[j], quartile1, quartile3)])\n",
    "    whiskers_min, whiskers_max = whiskers[:, 0], whiskers[:, 1]\n",
    "\n",
    "    inds = np.arange(1, len(medians) + 1)\n",
    "    axs[j].scatter(inds, medians, marker='o', color='white', s=30, zorder=3)\n",
    "    axs[j].vlines(inds, quartile1, quartile3, color='k', linestyle='-', lw=5)\n",
    "    axs[j].vlines(inds, whiskers_min, whiskers_max, color='k', linestyle='-', lw=1)\n",
    "    \n",
    "    if j == len(Total_Month_Arr):\n",
    "        set_axis_style(axs[j], month_arr)\n",
    "\n",
    "fig.text(0.005,0.5,\"Averaged Monthly Vegetation Cross-Edge Distance / m\", va='center', rotation='vertical')\n",
    "plt.xticks(new_d, month_arr)\n",
    "\n",
    "plt.savefig('Data/' + sitename + '/jpg_files/monthViolin', bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#array of colours for each of the averaged transect-analysis (add more if need be)\n",
    "colours = ['#ff0000','#0084ff','#ff00f7','#00fa0c', '#ffb300', '#00ffcc','#7b00ff']\n",
    "\n",
    "Rows = []\n",
    "\n",
    "with open('Data/'+sitename+'/vegetation_transect_time_series.csv', newline='') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "    for row in spamreader:\n",
    "        Rows.append(row[2:])\n",
    "\n",
    "cross_distance_condensed, standard_err_condensed, transect_condensed, Dates = Transects.transect_compiler(Rows, transect_proj, 100, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#Package this into Toolbox\n",
    "\n",
    "Rows = []\n",
    "\n",
    "with open('Data/'+sitename+'/vegetation_transect_time_series.csv', newline='') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "    for row in spamreader:\n",
    "        Rows.append(row[2:])\n",
    "        \n",
    "cross_distance_condensed = dict([])\n",
    "standard_err_condensed = dict([])\n",
    "transect_condensed = dict([])\n",
    "Dates = dict([])\n",
    "\n",
    "for i in range(len(transect_range)):\n",
    "    cross_arr = []\n",
    "    trans_arr = []\n",
    "    for j in range(transect_range[i][0],transect_range[i][1]):\n",
    "        try:\n",
    "            arr = []\n",
    "            for k in range(len(Rows)-1):\n",
    "                try:\n",
    "                    arr.append(float(Rows[k][j]))\n",
    "                except:\n",
    "                    arr.append(np.nan)\n",
    "            cross_arr.append(arr)\n",
    "            trans_arr.append(transect_proj[list(transect_proj.keys())[j]])\n",
    "        except:\n",
    "            continue\n",
    "    std = np.nanstd(cross_arr,0)\n",
    "    for j in range(len(std)):\n",
    "        std[j] = std[j]/(abs(transect_range[i][0]-transect_range[i][1]))**0.5\n",
    "    \n",
    "    NaN_mask = np.isfinite(np.nanmean(cross_arr,0))\n",
    "    cross_distance_condensed['Transect_'+str(transect_range[i][0])+'-'+str(transect_range[i][1])] = np.nanmean(cross_arr,0).astype(np.double)[NaN_mask]\n",
    "    standard_err_condensed['Transect_'+str(transect_range[i][0])+'-'+str(transect_range[i][1])] = std.astype(np.double)[NaN_mask]\n",
    "    Dates['Transect_'+str(transect_range[i][0])+'-'+str(transect_range[i][1])] = np.array(output['dates'])[NaN_mask]\n",
    "    transect_condensed['Transect_'+str(transect_range[i][0])+'-'+str(transect_range[i][1])] = np.mean(trans_arr,0).astype(np.double)#[NaN_mask]\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=[15,12], tight_layout=True)\n",
    "gs = gridspec.GridSpec(len(cross_distance_condensed),2, wspace=0.035, width_ratios=[4,1])\n",
    "gs.update(left=0.05, right=0.95, bottom=0.05, top=0.95, hspace=0.05)\n",
    "\n",
    "x = np.arange(datetime(1984,1,1), datetime(2022,1,1), timedelta(days=100)).astype(str)\n",
    "y = [0]*139\n",
    "\n",
    "for i,key in enumerate(cross_distance_condensed.keys()):\n",
    "    \n",
    "    if np.all(np.isnan(cross_distance_condensed[key])):\n",
    "        continue\n",
    "        \n",
    "    ax = fig.add_subplot(gs[i,0])\n",
    "    ax.grid(linestyle=':', color='0.5')\n",
    "    ax.set_ylim([min(cross_distance_condensed[key]- np.nanmedian(cross_distance_condensed[key]))-5,max(cross_distance_condensed[key]- np.nanmedian(cross_distance_condensed[key]))+5])\n",
    "    dates = matplotlib.dates.date2num(Dates[key])\n",
    "    ax.errorbar(dates, cross_distance_condensed[key]- np.nanmedian(cross_distance_condensed[key]), yerr = standard_err_condensed[key],fmt='-o',ecolor= 'k', color= colours[i], ms=6, mfc='w')\n",
    "    #ax.plot_date(Dates[key], cross_distance_condensed[key]- np.nanmedian(cross_distance_condensed[key]), xdate=True,fmt='-o', color= colours[i], ms=6, mfc='w')\n",
    "    #ax.fill_between(Dates[key], 0, cross_distance_condensed[key]- np.nanmedian(cross_distance_condensed[key]),alpha=0.5,color=colours[i])\n",
    "    \n",
    "    #ax.plot(x,y,color='k')\n",
    "    \n",
    "    #ax.text(0.5,0.95, key, bbox=dict(boxstyle=\"square\", ec='k',fc='w'), ha='center',va='top', transform=ax.transAxes, fontsize=14)\n",
    "    #ax.set_xlim(min(Dates[key]),max(Dates[key]))\n",
    "    #ax.set_xticklabels(linspace_datetime64(np.datetime64(min(Dates[key])),np.datetime64(max(Dates[key])), 7))#,rotation=45)\n",
    "    #ax.tick_params(axis='both', which='minor', labelsize=12)\n",
    "    #ax.grid(False,axis='x')\n",
    "    \n",
    "    ax.fill_between(dates, 0, cross_distance_condensed[key]- np.nanmedian(cross_distance_condensed[key]),alpha=0.5,color=colours[i])\n",
    "    ax.set_title(\"Transects:\"+str(transect_range[i][0])+\"-\"+str(transect_range[i][1]),backgroundcolor=transect_colour[i],color='white')\n",
    "    #ax.xaxis.set_major_locator(locator)\n",
    "    #ax.set_xticks(dates, minor=False)\n",
    "    ax.set_xticklabels(['1982','1986','1992','1998','2004','2010','2016','2020','2014','2018','2022'])\n",
    "    #ax.set_xticks(dates, minor=False)\n",
    "    #ax.set_xticklabels(Dates[key])\n",
    "    #locator=MaxNLocator(12)\n",
    "    #ax.xaxis.set_major_locator(locator)\n",
    "    if i!= len(cross_distance_condensed.keys())-1:\n",
    "        ax.set_xticklabels('')\n",
    "    #ax.set_xticks(Dates[key])\n",
    "\n",
    "    ax = fig.add_subplot(gs[i,1])\n",
    "    #ax.set_xlim([-50,50])\n",
    "    ax.set_xlim([0,0.020])\n",
    "    sns.distplot(cross_distance_condensed[key]- np.nanmedian(cross_distance_condensed[key]), bins=10, color=colours[i], ax=ax, vertical=True)\n",
    "    ax.set_yticklabels('')\n",
    "    \n",
    "    if i!= len(cross_distance_condensed.keys())-1:\n",
    "        ax.set_xticklabels('')\n",
    "        ax.set_xlabel('')\n",
    "        \n",
    "fig.text(0.01, 0.5, 'Cross Vegetation-Edge Distance / m', va='center', rotation='vertical', fontsize=13.8)\n",
    "\n",
    "plt.savefig('Data/' + sitename + '/jpg_files/crossEdgeDistances', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_sl_conv = Toolbox.convert_epsg(settings['reference_shoreline'], 32630, 27700)[:,:-1]\n",
    "\n",
    "vv = dict([])\n",
    "vv['1'] = [ref_sl_conv]\n",
    "\n",
    "#Displays produced lines/transects\n",
    "\n",
    "fig = plt.figure()#figsize=[15,8], tight_layout=True)\n",
    "plt.axis('equal')\n",
    "#plt.xlabel('Eastings')\n",
    "#plt.ylabel('Northings')\n",
    "plt.xlim(min(vv['1'][0][:,0]),max(vv['1'][0][:,0]))\n",
    "plt.xticks('')\n",
    "plt.yticks('')\n",
    "plt.ylim(min(vv['1'][0][:,1])-50,max(vv['1'][0][:,1])+50)\n",
    "plt.grid(linestyle=':', color='0.5')\n",
    "for i in range(len(vv['1'])):\n",
    "    sl = vv['1'][i]\n",
    "    date = vv['1'][i]\n",
    "    plt.plot(sl[:,0], sl[:,1], '.', color='k')#, label=date.strptime('%d-%m-%Y'))\n",
    " \n",
    "for i,key in enumerate(list(transect_condensed.keys())):\n",
    "    plt.plot(transect_condensed[key][0,0],transect_condensed[key][0,1], 'bo', color= colours[i], ms=5)\n",
    "    plt.plot(transect_condensed[key][:,0],transect_condensed[key][:,1],'k-', color= colours[i], lw=1)\n",
    "    plt.text(transect_condensed[key][1][0],transect_condensed[key][1][1], key, va='bottom', ha='right', bbox=dict(boxstyle=\"round\", ec='k',fc='w'), fontsize=10)\n",
    "\n",
    "plt.savefig('Data/' + sitename + '/jpg_files/refEdge_Transects', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=18\n",
    "produced = False\n",
    "while produced is False:\n",
    "    try:\n",
    "        print(i)\n",
    "        im_ms, georef, cloud_mask, im_extra, im_QA, im_nodata = Image_Processing.preprocess_single(i, 'S2', settings, polygon, dates)\n",
    "        produced = True\n",
    "        break\n",
    "    except:\n",
    "        i+=1\n",
    "        continue\n",
    "        \n",
    "im_RGB = Image_Processing.rescale_image_intensity(im_ms[:,:,[2,1,0]], cloud_mask, 99.9)\n",
    "fig = plt.figure()\n",
    "fig.set_size_inches([18,9])\n",
    "fig.set_tight_layout(True)\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax1.axis('off')\n",
    "ax1.imshow(im_RGB)\n",
    "plt.rcParams['savefig.jpeg_quality'] = 100\n",
    "\n",
    "fig.savefig(os.path.join('Data/' + sitename + '/jpg_files/SatelliteImg.jpg'), dpi=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_axes(fig):\n",
    "    for i, ax in enumerate(fig.axes):\n",
    "        ax.text(0.5, 0.5, \"ax%d\" % (i+1), va=\"center\", ha=\"center\")\n",
    "        ax.tick_params(labelbottom=False, labelleft=False)\n",
    "\n",
    "fig = plt.figure(constrained_layout=True, figsize=(15,12))\n",
    "\n",
    "gs = gridspec.GridSpec(6, 3, figure=fig, wspace=0.00001, hspace=0.1)\n",
    "\n",
    "ax1 = fig.add_subplot(gs[0,0])\n",
    "# identical to ax1 = plt.subplot(gs.new_subplotspec((0, 0), colspan=3))\n",
    "ax2 = fig.add_subplot(gs[0,1])\n",
    "ax3 = fig.add_subplot(gs[:2,2])\n",
    "ax4 = fig.add_subplot(gs[1, :2])\n",
    "#cross-dist\n",
    "cross1 = fig.add_subplot(gs[2, :])\n",
    "cross2 = fig.add_subplot(gs[3, :])\n",
    "cross3 = fig.add_subplot(gs[4, :])\n",
    "cross4 = fig.add_subplot(gs[5, :])\n",
    "\n",
    "fig.suptitle(\"GridSpec\")\n",
    "format_axes(fig)\n",
    "\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Big_percent = []\n",
    "for i,key in enumerate(cross_distance_condensed.keys()):\n",
    "    cross = cross_distance_condensed[key]- np.nanmedian(cross_distance_condensed[key])\n",
    "    percent_diff = []\n",
    "    for j in range(len(cross)):\n",
    "        percent_diff.append(100*(cross[j]-cross[0])/cross[0])\n",
    "        \n",
    "    Big_percent.append(percent_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transect_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Big_arr = []\n",
    "Big_datearr = []\n",
    "\n",
    "Year = [[]]*(2021-1984)\n",
    "\n",
    "for i in range(len(transect_range)):\n",
    "    percent_diff = []\n",
    "    dist_arr = []\n",
    "    date_arr = []\n",
    "    for j in range(transect_range[i][0],transect_range[i][1]):\n",
    "        KEY = 'Transect_'+str(j+1)\n",
    "        try:\n",
    "            a, b, c, d, e = Toolbox.Separate_TimeSeries_year(cross_distance, output_proj, KEY)\n",
    "            NaN_mask = np.isfinite(e)\n",
    "            dist_arr.append(list(np.array(e)[NaN_mask]))\n",
    "            date_arr.append(list(np.array(d)[NaN_mask]))\n",
    "            #percent_diff.append()\n",
    "        except:\n",
    "            continue\n",
    "    Big_arr.append(dist_arr)\n",
    "    Big_datearr.append(date_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Big_Percent = []\n",
    "\n",
    "for j in range(len(Big_arr)):\n",
    "    Medium_Percent_TransectRange = []\n",
    "    Year = dict([])\n",
    "    for i in range(len(Big_arr[j])):\n",
    "        for k in range(len(Big_arr[j][i])):\n",
    "            index = Big_datearr[j][i][k]-1984\n",
    "            if Year.get(str(index)) == None:\n",
    "                Year[str(index)] = []\n",
    "            Year[str(index)].append(Big_arr[j][i][index-1])\n",
    "            #print(len(Year[index-1]))\n",
    "    List_year = []\n",
    "    for v, key in enumerate(Year):\n",
    "        List_year.append(np.mean(Year[key]))\n",
    "    Big_Percent.append(List_year[1:])\n",
    "    #print(List_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Barz = []\n",
    "\n",
    "for i in range(len(Big_Percent)):\n",
    "    temp = []\n",
    "    for j in range(len(Big_Percent[i])):\n",
    "        temp.append(100*(Big_Percent[i][j]-Big_Percent[i][0])/Big_Percent[i][0])\n",
    "    Barz.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=(10, 12))\n",
    "for i in range(len(Barz)):\n",
    "    axs.barh(np.arange(len(Barz[i]))+(i/5), Barz[i], align='center',height= 0.2,color=colours[i],label='Transects: '+str(transect_range[i][0])+\"-\"+str(transect_range[i][1]) )\n",
    "axs.plot([0]*100,np.arange(0,37,0.37),'-.',color='k')\n",
    "axs.set_xlabel(\"% Change Since 1984\")\n",
    "#axs.set_xlim(-500,500)\n",
    "axs.set_yticks(np.arange(0,37,1))\n",
    "axs.set_yticklabels(list(np.array(d)[NaN_mask]))\n",
    "fig.text(0.25,0.85,\"Accretion (Relative to 1984)\")\n",
    "fig.text(0.58,0.85,\"Erosion (Relative to 1984)\")\n",
    "axs.legend(loc='lower right')\n",
    "for i in range(37):\n",
    "    axs.plot(np.arange(-500,500,10),[i-0.1]*100,'-.',color='k',alpha=0.7,linewidth=0.45)\n",
    "fig.savefig(os.path.join('Data/' + sitename + '/jpg_files/barBreakdown.jpg'), dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "x = np.arange(n)\n",
    "a = np.random.rand(n)\n",
    "b = np.random.rand(n)\n",
    "c = np.random.rand(n)\n",
    "\n",
    "fig, axs = plt.subplots(2,1,figsize=(10,8))\n",
    "\n",
    "axs[0].bar(x, a, width=0.3, facecolor='b', edgecolor='b', linewidth=3, alpha=.5)\n",
    "axs[0].bar(x+0.3, b, width=0.3, facecolor='r', edgecolor='r', linewidth=3, alpha=.5)\n",
    "axs[0].bar(x+0.6, c, width=0.3, facecolor='g', edgecolor='g', linewidth=3, alpha=.5)\n",
    "\n",
    "axs[1].bar(x, a, width=1/3, facecolor='b', alpha=.5, linewidth=0)\n",
    "axs[1].bar(x+1/3, b, width=1/3, facecolor='r', alpha=.5, linewidth=0)\n",
    "axs[1].bar(x+2/3, c, width=1/3, facecolor='g', alpha=.5, linewidth=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
