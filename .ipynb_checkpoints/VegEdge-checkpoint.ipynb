{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VegEdge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import warnings\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import mpl_toolkits as mpl\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns; sns.set()\n",
    "import math\n",
    "import geemap\n",
    "import ee\n",
    "import pprint\n",
    "import geopandas as gpd\n",
    "import matplotlib.cm as cm\n",
    "import pyproj\n",
    "import scipy\n",
    "import csv\n",
    "import math\n",
    "from matplotlib import gridspec\n",
    "from datetime import date, datetime, timezone, timedelta\n",
    "from Elves import Download, Image_Processing, Shoreline, Toolbox, Transects, VegetationLine\n",
    "from mpl_toolkits.axes_grid1.inset_locator import zoomed_inset_axes, mark_inset\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from sklearn.datasets import load_diabetes\n",
    "from shapely import geometry\n",
    "from shapely.geometry import Point, LineString\n",
    "from IPython.display import clear_output\n",
    "from scipy import optimize\n",
    "from pyproj import Proj\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "matplotlib.use('Qt5Agg')\n",
    "plt.ion\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Region of Interest Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two options for image retrieval: 1st involes selecting region for the map generated below; 2nd involes inputting lat,lon coords manually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Option 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Run this cell to generate a map. Use the polygon drawing tool on the left-hand side to \n",
    "draw out the region of coast you're interested in.\n",
    "\"\"\"\n",
    "\n",
    "Map = geemap.Map(center=[0,0],zoom=2)\n",
    "Map.add_basemap('HYBRID')\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi = Map.user_roi.geometries().getInfo()[0]['coordinates']\n",
    "polygon = [[roi[0][0],roi[0][3],roi[0][1],roi[0][2]]]\n",
    "point = ee.Geometry.Point(roi[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Option 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##Below are example coordinates\n",
    "\n",
    "##ST ANDREWS\n",
    "lonmin, lonmax = -2.842023, -2.774955\n",
    "latmin, latmax = 56.338343, 56.368490\n",
    "\n",
    "##FELIXSTOWE\n",
    "#lonmin, lonmax = 1.316128, 1.370888\n",
    "#latmin, latmax = 51.930771, 51.965265\n",
    "\n",
    "##BAY OF SKAILL\n",
    "#lonmin, lonmax = -3.351555, -3.332693\n",
    "#latmin, latmax = 59.048456, 59.057759\n",
    "\n",
    "##SHINGLE STREET\n",
    "#lonmin, lonmax = 1.446131, 1.460008\n",
    "#latmin, latmax = 52.027039, 52.037448\n",
    "\n",
    "##COVEHITHE\n",
    "#\n",
    "\n",
    "point = ee.Geometry.Point([lonmin, latmin])\n",
    "polygon = [[[lonmin, latmin],[lonmax, latmin],[lonmin, latmax],[lonmax, latmax]]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images available between 1940-05-01 and 2021-12-02:\n",
      "- In Landsat Tier 1 & Sentinel-2 Level-1C:\n",
      "  L5: 344 images\n",
      "  L8: 290 images\n",
      "  S2: 665 images\n",
      "  Total: 1299 images\n",
      "- In Landsat Tier 2:\n",
      "  L5: 422 images\n",
      "  L8: 110 images\n",
      "  Total: 532 images\n"
     ]
    }
   ],
   "source": [
    "# it's recommended to convert the polygon to the smallest rectangle (sides parallel to coordinate axes)       \n",
    "polygon = Toolbox.smallest_rectangle(polygon)\n",
    "\n",
    "# date range\n",
    "dates = ['1940-05-01', '2021-12-02']\n",
    "\n",
    "years = list(Toolbox.daterange(datetime.strptime(dates[0],'%Y-%m-%d'), datetime.strptime(dates[1],'%Y-%m-%d')))\n",
    "\n",
    "# satellite missions\n",
    "# Input a list of containing any/all of 'L5', 'L8', 'S2'\n",
    "sat_list = ['L5','L8','S2']\n",
    "\n",
    "projection_epsg = 27700\n",
    "image_epsg = 32630\n",
    "\n",
    "# name of the site\n",
    "sitename = 'ResearchData2'\n",
    "# directory where the data will be stored\n",
    "filepath = os.path.join(os.getcwd(), 'Data')\n",
    "\n",
    "# put all the inputs into a dictionnary\n",
    "inputs = {'polygon': polygon, 'dates': dates, 'sat_list': sat_list, 'sitename': sitename, 'filepath':filepath}\n",
    "\n",
    "direc = os.path.join(filepath, sitename)\n",
    "\n",
    "if os.path.isdir(direc) is False:\n",
    "    os.mkdir(direc)\n",
    "\n",
    "# before downloading the images, check how many images are available for your inputs\n",
    "Download.check_images_available(inputs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata already exists and was loaded\n"
     ]
    }
   ],
   "source": [
    "Sat = Toolbox.image_retrieval(point,dates, sat_list)\n",
    "metadata = Toolbox.metadata_collection(sat_list, Sat, filepath, sitename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Veg Line - Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BasePath = 'Data/' + sitename + '/Veglines'\n",
    "\n",
    "if os.path.isdir(BasePath) is False:\n",
    "    os.mkdir(BasePath)\n",
    "\n",
    "settings = {\n",
    "    # general parameters:\n",
    "    'cloud_thresh': 0.20,        # threshold on maximum cloud cover\n",
    "    'output_epsg': image_epsg,     # epsg code of spatial reference system desired for the output   \n",
    "    # quality control:\n",
    "    'check_detection': False,    # if True, shows each shoreline detection to the user for validation\n",
    "    'adjust_detection': False,  # if True, allows user to adjust the postion of each shoreline by changing the threhold\n",
    "    'save_figure': False,        # if True, saves a figure showing the mapped shoreline for each image\n",
    "    # [ONLY FOR ADVANCED USERS] shoreline detection parameters:\n",
    "    'min_beach_area': 50,     # minimum area (in metres^2) for an object to be labelled as a beach\n",
    "    'buffer_size': 250,         # radius (in metres) for buffer around sandy pixels considered in the shoreline detection\n",
    "    'min_length_sl': 100,       # minimum length (in metres) of shoreline perimeter to be valid\n",
    "    'cloud_mask_issue': False,  # switch this parameter to True if sand pixels are masked (in black) on many images  \n",
    "    'sand_color': 'bright',    # 'default', 'dark' (for grey/black sand beaches) or 'bright' (for white sand beaches)\n",
    "    # add the inputs defined previously\n",
    "    'inputs': inputs,\n",
    "    'projection_epsg': projection_epsg,\n",
    "    'year_list': years,\n",
    "    'hausdorff_threshold':350000000000000000000000000000000000000000000000000\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Digitize a reference vegetation line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My nice new code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Draw reference line onto the map then run the next cell\n",
    "\n",
    "Map = geemap.Map(center=[0,0],zoom=2)\n",
    "Map.add_basemap('HYBRID')\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "referenceLine = Map.user_roi.geometries().getInfo()[0]['coordinates']\n",
    "\n",
    "for i in range(len(referenceLine)):\n",
    "    #referenceLine[i][0], referenceLine[i][1] = referenceLine[i][1], referenceLine[i][0]\n",
    "    referenceLine[i] = list(referenceLine[i])\n",
    "\n",
    "referenceLine = Toolbox.convert_epsg(np.array(referenceLine),4326,32630)\n",
    "settings['reference_shoreline'] = referenceLine\n",
    "settings['max_dist_ref'] = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The old code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference shoreline already exists and was loaded\n"
     ]
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "settings['reference_shoreline'] = Image_Processing.get_reference_sl(metadata, settings, polygon, dates)\n",
    "settings['max_dist_ref'] = 150 # max distance (in meters) allowed from the reference shoreline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracts vegetation lines from all selected images. This'll take a while..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "output, output_latlon, output_proj = VegetationLine.extract_veglines(metadata, settings, polygon, dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alternatively, load the output file if previously processed\n",
    "filepath = os.path.join(inputs['filepath'], sitename)\n",
    "with open(os.path.join(filepath, sitename + '_output.pkl'), 'rb') as f:\n",
    "    output = pickle.load(f)\n",
    "with open(os.path.join(filepath, sitename + '_output_latlon.pkl'), 'rb') as f:\n",
    "    output_latlon = pickle.load(f)\n",
    "with open(os.path.join(filepath, sitename + '_output_proj.pkl'), 'rb') as f:\n",
    "    output_proj = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = Toolbox.remove_duplicates(output) # removes duplicates (images taken on the same date by the same satellite)\n",
    "output_latlon = Toolbox.remove_duplicates(output_latlon)\n",
    "output_proj = Toolbox.remove_duplicates(output_proj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visual Display of Vegetation Lines. Will tank your PC if you've got lots of lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Creates map object centred at ROI + adds compiled satellite image as base-layer\n",
    "#Map = geemap.Map(center=[polygon[0][0][1],polygon[0][0][0]],zoom=12)\n",
    "#Map.add_basemap('HYBRID')\n",
    "\n",
    "#Generates colours for lines to be drawn in. Check out https://seaborn.pydata.org/tutorial/color_palettes.html for colour options...\n",
    "palette = sns.color_palette(\"bright\", len(output['shorelines']))\n",
    "palette = palette.as_hex()\n",
    "\n",
    "#Choose 'points' or 'lines' for the layer geometry\n",
    "geomtype = 'points'\n",
    "\n",
    "for i in range(len(output['shorelines'])):\n",
    "    shore = dict([])\n",
    "    if len(output_latlon['shorelines'][i])==0:\n",
    "        continue\n",
    "    shore = {'dates':[output_latlon['dates'][i]], 'shorelines':[output_latlon['shorelines'][i]], 'filename':[output_latlon['filename'][i]], 'cloud_cover':[output_latlon['cloud_cover'][i]], 'idx':[output_latlon['idx'][i]], 'Otsu_threshold':[output_latlon['Otsu_threshold'][i]], 'satname':[output_latlon['satname'][i]]}\n",
    "    gdf = Toolbox.output_to_gdf(shore, geomtype)\n",
    "    Line = geemap.geopandas_to_ee(gdf, geodesic=True)\n",
    "    Map.addLayer(Line,{'color': str(palette[i])},'coast'+str(i))\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saves the veglines as individual shape-files locally under /Veglines.\n",
    "direc = os.path.join(filepath, '/Veglines')\n",
    "geomtype = 'lines'\n",
    "name_prefix = 'Data/' + sitename + '/Veglines'\n",
    "\n",
    "if os.path.isdir(direc) is False:\n",
    "    os.mkdir(direc)\n",
    "\n",
    "Toolbox.save_shapefiles(output_latlon, geomtype, name_prefix, sitename)\n",
    "\n",
    "ref_line = np.delete(settings['reference_shoreline'],2,1)\n",
    "ref = {'dates':['3000-12-30'], 'shorelines':[ref_line], 'filename':[0], 'cloud_cover':[0], 'geoaccuracy':[0], 'idx':[0], 'Otsu_threshold':[0], 'satname':[0]}\n",
    "    \n",
    "Toolbox.save_shapefiles(ref, geomtype, name_prefix, sitename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Produces Transects and Coast shape-files for the reference line\n",
    "\n",
    "SmoothingWindowSize = 21\n",
    "NoSmooths = 100\n",
    "TransectSpacing = 10\n",
    "DistanceInland = 350\n",
    "DistanceOffshore = 350\n",
    "BasePath = 'Data/' + sitename + '/Veglines'\n",
    "\n",
    "Transects.produce_transects(SmoothingWindowSize, NoSmooths, TransectSpacing, DistanceInland, DistanceOffshore, image_epsg, sitename, BasePath + '/' + sitename + '_referenceLine')\n",
    "\n",
    "#(Optional) Produces transects for all produced lines\n",
    "#Transects.produce_transects_all(SmoothingWindowSize, NoSmooths, TransectSpacing, DistanceInland, DistanceOffshore, projection_epsg, BasePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Defines all transects in a library.\n",
    "\n",
    "TransectSpec =  '/' + sitename + '_referenceLine/Transect.shp'\n",
    "geo = gpd.read_file(BasePath+TransectSpec)\n",
    "\n",
    "transect_latlon, transect_proj = Transects.stuffIntoLibrary(geo, image_epsg, projection_epsg, filepath, sitename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Or just load them if already produced\n",
    "with open(os.path.join(filepath, sitename + '_transect_proj' + '.pkl'), 'rb') as f:\n",
    "    transect_proj = pickle.load(f)\n",
    "with open(os.path.join(filepath, sitename + '_transect_latlon' + '.pkl'), 'rb') as f:\n",
    "    transect_latlon = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings['along_dist'] = 50\n",
    "cross_distance = Transects.compute_intersection(output_proj, transect_proj, settings, 'vegetation_') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Or just load it if it already exists :)\n",
    "\n",
    "cross_distance = dict([])\n",
    "\n",
    "with open('Data/'+sitename+'/vegetation_transect_time_series.csv', newline='') as csvfile:\n",
    "    spamreader = csv.DictReader(csvfile, delimiter=',', quotechar='|')\n",
    "    for lines in spamreader:\n",
    "        for i in range(len(lines)-2):\n",
    "            cross_distance['Transect_'+str(i+1)] = []\n",
    "\n",
    "with open('Data/'+sitename+'/vegetation_transect_time_series.csv', newline='') as csvfile:\n",
    "    spamreader = csv.DictReader(csvfile, delimiter=',', quotechar='|')\n",
    "    for lines in spamreader:\n",
    "        for i in range(len(lines)-2):\n",
    "            transect_name = 'Transect Transect_' + str(i+1)\n",
    "            try:\n",
    "                cross_distance['Transect_'+str(i+1)].append(float(lines[transect_name]))\n",
    "            except:\n",
    "                cross_distance['Transect_'+str(i+1)].append(np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis - Vegetation Edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Displays produced lines/transects\n",
    "\n",
    "fig = plt.figure(figsize=[15,8], tight_layout=True)\n",
    "plt.axis('equal')\n",
    "plt.xlabel('Eastings')\n",
    "plt.ylabel('Northings')\n",
    "#plt.xlim(509000,513000)\n",
    "#plt.ylim(6244400,6247250)\n",
    "plt.grid(linestyle=':', color='0.5')\n",
    "for i in range(len(output_proj['shorelines'])):\n",
    "    sl = output_proj['shorelines'][i]\n",
    "    date = output_proj['dates'][i]\n",
    "    plt.plot(sl[:,0], sl[:,1], '.')#, label=date.strptime('%d-%m-%Y'))\n",
    " \n",
    "for i,key in enumerate(list(transect_proj.keys())):\n",
    "    plt.plot(transect_proj[key][0,0],transect_proj[key][0,1], 'bo', ms=5)\n",
    "    plt.plot(transect_proj[key][:,0],transect_proj[key][:,1],'k-',lw=1)\n",
    "    #plt.text(transects_proj[key][0,0]-100, transects_proj[key][0,1]+100, key, va='center', ha='right', bbox=dict(boxstyle=\"square\", ec='k',fc='w'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Displays the transects\n",
    "\n",
    "for i,key in enumerate(list(transect_proj.keys())):\n",
    "    plt.plot(transect_proj[key][0,0],transect_proj[key][0,1], 'bo', ms=5)\n",
    "    plt.plot(transect_proj[key][:,0],transect_proj[key][:,1],'k-',lw=1)\n",
    "    #plt.text(transects_proj[key][0,0]-100, transects_proj[key][0,1]+100, key, va='center', ha='right', bbox=dict(boxstyle=\"square\", ec='k',fc='w'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Displays the lines\n",
    "\n",
    "fig = plt.figure(figsize=[15,8])\n",
    "plt.axis('equal')\n",
    "plt.xlabel('Eastings')\n",
    "plt.ylabel('Northings')\n",
    "plt.grid(linestyle=':', color='0.5')\n",
    "for i in range(len(output_proj['shorelines'])):\n",
    "    sl = output_proj['shorelines'][i]\n",
    "    date = output_proj['dates'][i]\n",
    "    plt.plot(sl[:,0], sl[:,1], '.')#, label=date.strftime('%d-%m-%Y'))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Cross-distance plots for ALL transects (do not bother if you are considering a LOT of transects)\n",
    "\n",
    "fig = plt.figure(figsize=[15,12], tight_layout=True)\n",
    "gs = gridspec.GridSpec(len(cross_distance),2, wspace=0.035, width_ratios=[3,1])\n",
    "gs.update(left=0.05, right=0.95, bottom=0.05, top=0.95, hspace=0.2)\n",
    "for i,key in enumerate(cross_distance.keys()):\n",
    "    if np.all(np.isnan(cross_distance[key])):\n",
    "        continue\n",
    "    ax = fig.add_subplot(gs[i,0])\n",
    "    ax.grid(linestyle=':', color='0.5')\n",
    "    ax.set_ylim([-100,110])\n",
    "    ax.plot(output['dates'], cross_distance[key]- np.nanmedian(cross_distance[key]), '-o', ms=6, mfc='w')\n",
    "    #ax.set_ylabel('distance [m]', fontsize=12)\n",
    "    ax.text(0.5,0.95, key, bbox=dict(boxstyle=\"square\", ec='k',fc='w'), ha='center',va='top', transform=ax.transAxes, fontsize=14)\n",
    "    if i!= len(cross_distance.keys())-1:\n",
    "        ax.set_xticklabels('')\n",
    "    ax = fig.add_subplot(gs[i,1])\n",
    "    #ax.set_xlim([-50,50])\n",
    "    ax.set_xlim([0,0.015])\n",
    "    sns.distplot(cross_distance[key]- np.nanmedian(cross_distance[key]), bins=10, color=\"b\", ax=ax, vertical=True)\n",
    "    ax.set_yticklabels('')\n",
    "    if i!= len(cross_distance.keys())-1:\n",
    "        ax.set_xticklabels('')\n",
    "fig.text(0.01, 0.5, 'Cross-Shore Distance / m', va='center', rotation='vertical', fontsize=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transect_range = [[0, 50],[51,110],[111,180], [181,275],[276,376],[377,479],[480,580],[580,639],[640,661]]\n",
    "#transect_colour = sns.color_palette(\"bright\", len(transect_range))\n",
    "colours = ['#ff0000','#0084ff','#ff00f7','#00fa0c', '#ffb300', '#00ffcc','#7b00ff','#5315e6','#97cc25']\n",
    "transect_colour = colours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In this cell, you can iterate on transect range (we will use these ranges to analyse specific regions of the edge)\n",
    "\n",
    "fig = plt.figure(figsize=[15,8], tight_layout=True)\n",
    "plt.axis('equal')\n",
    "plt.xlabel('Eastings')\n",
    "plt.ylabel('Northings')\n",
    "#plt.xlim(509000,513000)\n",
    "#plt.ylim(6244400,6247250)\n",
    "plt.grid(linestyle=':', color='0.5')\n",
    "for i in range(len(output_proj['shorelines'])):\n",
    "    sl = output_proj['shorelines'][i]\n",
    "    date = output_proj['dates'][i]\n",
    "    plt.plot(sl[:,0], sl[:,1], '.')#, label=date.strptime('%d-%m-%Y'))\n",
    "\n",
    "if transect_range == 'full':\n",
    "    transect_range = [[0,len(transect_proj.keys())]]   \n",
    "\n",
    "for i,key in enumerate(list(transect_proj.keys())):\n",
    "    for j in range(len(transect_range)):\n",
    "        if transect_range[j][0] <= i <= transect_range[j][1]:\n",
    "            plt.plot(transect_proj[key][0,0],transect_proj[key][0,1], 'bo', ms=5,color=transect_colour[j])\n",
    "            plt.plot(transect_proj[key][:,0],transect_proj[key][:,1],'k-',lw=1,color=transect_colour[j])\n",
    "    #plt.text(transects_proj[key][0,0]-100, transects_proj[key][0,1]+100, key, va='center', ha='right', bbox=dict(boxstyle=\"square\", ec='k',fc='w'))\n",
    "\n",
    "plt.savefig('Data/' + sitename + '/jpg_files/transectsFull', bbox_inches='tight')\n",
    "  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Year by Year\n",
    "\n",
    "from matplotlib import rcParams\n",
    "rcParams.update({'figure.autolayout': True})\n",
    "\n",
    "fig, axs = plt.subplots(len(transect_range),sharex=True,figsize=(10, 12))\n",
    "fig.text(0.005, 0.5, \"Average Yearly Vegetation Cross-Edge Distance / m\", va='center', rotation='vertical', fontsize=12)\n",
    "\n",
    "for i in range(len(transect_range)):\n",
    "    axs[i].set_title(\"Transects:\"+str(transect_range[i][0])+\"-\"+str(transect_range[i][1]),backgroundcolor=transect_colour[i],color='white')\n",
    "    if i != len(transect_range)-1:\n",
    "        axs[i].xaxis.set_visible(False)\n",
    "    if i == len(transect_range)-1:\n",
    "        axs[i].set_xlabel(\"Year\", fontsize=12)\n",
    "    for j in range(transect_range[i][0],transect_range[i][1]):\n",
    "        KEY = 'Transect_'+str(j+1)\n",
    "        try:\n",
    "            a, b, c, d, e = Toolbox.Separate_TimeSeries_year(cross_distance, output_proj, KEY)\n",
    "            NaN_mask = np.isfinite(e)\n",
    "            axs[i].plot(np.array(d)[NaN_mask],np.array(e)[NaN_mask])\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "plt.savefig('Data/' + sitename + '/jpg_files/avgYearlyVegPosition', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Good at looking at seasonal patterns. Takes a while.\n",
    "\n",
    "#plt.figure(figsize=[15,12])\n",
    "\n",
    "months = [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"June\", \"July\", \"Aug\", \"Sept\", \"Oct\", \"Nov\", \"Dec\"]\n",
    "Month_dict = {\"Jan\":[], \"Feb\":[], \"Mar\":[], \"Apr\":[], \"May\":[], \"June\":[], \"July\":[], \"Aug\":[], \"Sept\":[], \"Oct\":[], \"Nov\":[], \"Dec\":[]}\n",
    "\n",
    "Total_Month_Arr = []\n",
    "test1 = []\n",
    "test2 = []\n",
    "\n",
    "fig, axs = plt.subplots(len(transect_range),sharex=True,figsize=(10, 12))\n",
    "\n",
    "for l in range(len(transect_range)):\n",
    "\n",
    "    for i in range(transect_range[l][0],transect_range[l][1]):\n",
    "        KEY = 'Transect_'+str(i+1)\n",
    "        try:\n",
    "            a, b, c, d, e = Toolbox.Separate_TimeSeries_month(cross_distance, output_proj,KEY)\n",
    "\n",
    "            zipped_lists = zip(d,e)\n",
    "            s = sorted(zipped_lists)\n",
    "            tuples = zip(s)\n",
    "\n",
    "            new_d = []\n",
    "            new_e = []\n",
    "\n",
    "            sortedList = [list(tuple) for tuple in  tuples]\n",
    "\n",
    "            for v in range(len(sortedList)):\n",
    "                new_d.append(sortedList[v][0][0])\n",
    "                new_e.append(sortedList[v][0][1])\n",
    "\n",
    "            month_arr = []\n",
    "            for j in range(len(d)):\n",
    "                a = datetime.strptime(str(new_d[j]),'%m')\n",
    "                month_arr.append(a.strftime('%b'))\n",
    "\n",
    "            axs[l].scatter(month_arr,new_e,label=KEY)\n",
    "            test1.append(new_d)\n",
    "            test2.append(new_e)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    avg = []\n",
    "    st_err = []\n",
    "    Total_organised = []\n",
    "    temp = []\n",
    "\n",
    "    for k in range(len(test2[0])):\n",
    "        for h in range(len(test2)):\n",
    "            temp.append(test2[h][k])\n",
    "        Total_organised.append(temp)\n",
    "        avg.append(np.nanmean(temp))\n",
    "        st_err.append(np.nanstd(temp)/(len(temp)**0.5))\n",
    "        temp = []\n",
    "    \n",
    "    Total_Month_Arr.append(Total_organised)\n",
    "    \n",
    "    #plt.errorbar(month_arr,avg, yerr=st_err, color='k')\n",
    "    axs[l].scatter(month_arr,avg, color='k', s=50, marker='x')\n",
    "\n",
    "    #plt.legend()\n",
    "    axs[l].set_title(\"Transects:\"+str(transect_range[l][0])+\"-\"+str(transect_range[l][1]),backgroundcolor=transect_colour[l],color='white')\n",
    "\n",
    "fig.text(0.01,0.5,\"Averaged Monthly Vegetation Cross-Edge Distance / m\", va='center', rotation='vertical')\n",
    "plt.xlabel(\"Month\")\n",
    "\n",
    "plt.savefig('Data/' + sitename + '/jpg_files/monthScatter', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(len(transect_range),sharex=True,figsize=(10, 12))\n",
    "\n",
    "for j in range(len(Total_Month_Arr)):\n",
    "    \n",
    "    axs[j].set_title(\"Transects:\"+str(transect_range[j][0])+\"-\"+str(transect_range[j][1]),backgroundcolor=transect_colour[j],color='white')\n",
    "    axs[j].boxplot(Total_Month_Arr[j],notch=True, flierprops = dict(marker='o', markersize=8, linestyle='none', markeredgecolor='r'))\n",
    "\n",
    "fig.text(0.01,0.5,\"Averaged Monthly Vegetation Cross-Edge Distance / m\", va='center', rotation='vertical')\n",
    "plt.xticks(new_d, month_arr)\n",
    "\n",
    "plt.savefig('Data/' + sitename + '/jpg_files/monthBox', bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjacent_values(vals, q1, q3):\n",
    "    upper_adjacent_value = q3 + (q3 - q1) * 1.5\n",
    "    upper_adjacent_value = np.clip(upper_adjacent_value, q3, vals[-1])\n",
    "\n",
    "    lower_adjacent_value = q1 - (q3 - q1) * 1.5\n",
    "    lower_adjacent_value = np.clip(lower_adjacent_value, vals[0], q1)\n",
    "    return lower_adjacent_value, upper_adjacent_value\n",
    "\n",
    "\n",
    "def set_axis_style(ax, labels):\n",
    "    ax.xaxis.set_tick_params(direction='out')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.set_xticks(np.arange(1, len(labels) + 1))\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.set_xlim(0.25, len(labels) + 0.75)\n",
    "    #ax.set_xlabel('Sample name')\n",
    "\n",
    "fig, axs = plt.subplots(len(transect_range),sharex=True,figsize=(10, 12))\n",
    "\n",
    "for j in range(len(Total_Month_Arr)):\n",
    "    \n",
    "    axs[j].set_title(\"Transects:\"+str(transect_range[j][0])+\"-\"+str(transect_range[j][1]),backgroundcolor=transect_colour[j],color='white')\n",
    "    parts = axs[j].violinplot(Total_Month_Arr[j], showmeans=False, showmedians=False, showextrema=False)\n",
    "\n",
    "    for pc in parts['bodies']:\n",
    "        pc.set_facecolor(transect_colour[j])\n",
    "        pc.set_edgecolor('black')\n",
    "        pc.set_alpha(0.7)\n",
    "\n",
    "    quartile1, medians, quartile3 = np.percentile(Total_Month_Arr[j], [25, 50, 75], axis=1)\n",
    "    whiskers = np.array([\n",
    "        adjacent_values(sorted_array, q1, q3)\n",
    "        for sorted_array, q1, q3 in zip(Total_Month_Arr[j], quartile1, quartile3)])\n",
    "    whiskers_min, whiskers_max = whiskers[:, 0], whiskers[:, 1]\n",
    "\n",
    "    inds = np.arange(1, len(medians) + 1)\n",
    "    axs[j].scatter(inds, medians, marker='o', color='white', s=30, zorder=3)\n",
    "    axs[j].vlines(inds, quartile1, quartile3, color='k', linestyle='-', lw=5)\n",
    "    axs[j].vlines(inds, whiskers_min, whiskers_max, color='k', linestyle='-', lw=1)\n",
    "    \n",
    "    if j == len(Total_Month_Arr):\n",
    "        set_axis_style(axs[j], month_arr)\n",
    "\n",
    "fig.text(0.005,0.5,\"Averaged Monthly Vegetation Cross-Edge Distance / m\", va='center', rotation='vertical')\n",
    "plt.xticks(new_d, month_arr)\n",
    "\n",
    "plt.savefig('Data/' + sitename + '/jpg_files/monthViolin', bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rows = []\n",
    "\n",
    "with open('Data/'+sitename+'/vegetation_transect_time_series.csv', newline='') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "    for row in spamreader:\n",
    "        Rows.append(row[2:])\n",
    "\n",
    "cross_distance_condensed, standard_err_condensed, transect_condensed, Dates = Transects.transect_compiler(Rows, transect_proj, transect_range, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=[15,12], tight_layout=True)\n",
    "gs = gridspec.GridSpec(len(cross_distance_condensed),2, wspace=0.035, width_ratios=[4,1])\n",
    "gs.update(left=0.05, right=0.95, bottom=0.05, top=0.95, hspace=0.05)\n",
    "\n",
    "x = np.arange(datetime(1984,1,1), datetime(2022,1,1), timedelta(days=100)).astype(str)\n",
    "y = [0]*139\n",
    "\n",
    "for i,key in enumerate(cross_distance_condensed.keys()):\n",
    "    \n",
    "    if np.all(np.isnan(cross_distance_condensed[key])):\n",
    "        continue\n",
    "    \n",
    "    ax = fig.add_subplot(gs[i,0])\n",
    "    ax.grid(linestyle=':', color='0.5')\n",
    "    ax.set_ylim([min(cross_distance_condensed[key]- np.nanmedian(cross_distance_condensed[key]))-5,max(cross_distance_condensed[key]- np.nanmedian(cross_distance_condensed[key]))+5])\n",
    "    dates = matplotlib.dates.date2num(Dates[key])\n",
    "    ax.errorbar(dates, cross_distance_condensed[key]- np.nanmedian(cross_distance_condensed[key]), yerr = standard_err_condensed[key],fmt='-o',ecolor= 'k', color= colours[i], ms=6, mfc='w')\n",
    "\n",
    "    ax.fill_between(dates, 0, cross_distance_condensed[key]- np.nanmedian(cross_distance_condensed[key]),alpha=0.5,color=colours[i])\n",
    "    ax.set_title(\"Transects:\"+str(transect_range[i][0])+\"-\"+str(transect_range[i][1]),backgroundcolor=transect_colour[i],color='white')\n",
    "\n",
    "    ax.set_xticklabels(['1982','1986','1992','1998','2004','2010','2016','2020','2014','2018','2022'])\n",
    "\n",
    "    if i!= len(cross_distance_condensed.keys())-1:\n",
    "        ax.set_xticklabels('')\n",
    "\n",
    "    ax = fig.add_subplot(gs[i,1])\n",
    "    ax.set_xlim([0,0.020])\n",
    "    sns.distplot(cross_distance_condensed[key]- np.nanmedian(cross_distance_condensed[key]), bins=10, color=colours[i], ax=ax, vertical=True)\n",
    "    ax.set_yticklabels('')\n",
    "    \n",
    "    if i!= len(cross_distance_condensed.keys())-1:\n",
    "        ax.set_xticklabels('')\n",
    "        ax.set_xlabel('')\n",
    "        \n",
    "fig.text(0.01, 0.5, 'Cross Vegetation-Edge Distance / m', va='center', rotation='vertical', fontsize=13.8)\n",
    "\n",
    "plt.savefig('Data/' + sitename + '/jpg_files/crossEdgeDistances', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_sl_conv = Toolbox.convert_epsg(settings['reference_shoreline'], 32630, 27700)[:,:-1]\n",
    "\n",
    "vv = dict([])\n",
    "vv['1'] = [ref_sl_conv]\n",
    "\n",
    "#Displays produced lines/transects\n",
    "\n",
    "fig = plt.figure()#figsize=[15,8], tight_layout=True)\n",
    "plt.axis('equal')\n",
    "#plt.xlabel('Eastings')\n",
    "#plt.ylabel('Northings')\n",
    "plt.xlim(min(vv['1'][0][:,0]),max(vv['1'][0][:,0]))\n",
    "#plt.xticks('')\n",
    "#plt.yticks('')\n",
    "plt.ylim(min(vv['1'][0][:,1])-50,max(vv['1'][0][:,1])+50)\n",
    "plt.grid(linestyle=':', color='0.5')\n",
    "for i in range(len(vv['1'])):\n",
    "    sl = vv['1'][i]\n",
    "    date = vv['1'][i]\n",
    "    plt.plot(sl[:,0], sl[:,1], '.', color='k')#, label=date.strptime('%d-%m-%Y'))\n",
    " \n",
    "for i,key in enumerate(list(transect_condensed.keys())):\n",
    "    plt.plot(transect_condensed[key][0,0],transect_condensed[key][0,1], 'bo', color= colours[i], ms=5)\n",
    "    plt.plot(transect_condensed[key][:,0],transect_condensed[key][:,1],'k-', color= colours[i], lw=1)\n",
    "    plt.text(transect_condensed[key][1][0],transect_condensed[key][1][1], key, va='bottom', ha='right', bbox=dict(boxstyle=\"round\", ec='k',fc='w'), fontsize=10)\n",
    "\n",
    "plt.savefig('Data/' + sitename + '/jpg_files/refEdge_Transects', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Big_percent = []\n",
    "for i,key in enumerate(cross_distance_condensed.keys()):\n",
    "    cross = cross_distance_condensed[key]- np.nanmedian(cross_distance_condensed[key])\n",
    "    percent_diff = []\n",
    "    for j in range(len(cross)):\n",
    "        percent_diff.append(100*(cross[j]-cross[0])/cross[0])\n",
    "        \n",
    "    Big_percent.append(percent_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Big_arr = []\n",
    "Big_datearr = []\n",
    "\n",
    "Year = [[]]*(2021-1984)\n",
    "\n",
    "for i in range(len(transect_range)):\n",
    "    percent_diff = []\n",
    "    dist_arr = []\n",
    "    date_arr = []\n",
    "    for j in range(transect_range[i][0],transect_range[i][1]):\n",
    "        KEY = 'Transect_'+str(j+1)\n",
    "        try:\n",
    "            a, b, c, d, e = Toolbox.Separate_TimeSeries_year(cross_distance, output_proj, KEY)\n",
    "            NaN_mask = np.isfinite(e)\n",
    "            dist_arr.append(list(np.array(e)[NaN_mask]))\n",
    "            date_arr.append(list(np.array(d)[NaN_mask]))\n",
    "            #percent_diff.append()\n",
    "        except:\n",
    "            continue\n",
    "    Big_arr.append(dist_arr)\n",
    "    Big_datearr.append(date_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Big_Percent = []\n",
    "\n",
    "for j in range(len(Big_arr)):\n",
    "    Medium_Percent_TransectRange = []\n",
    "    Year = dict([])\n",
    "    for i in range(len(Big_arr[j])):\n",
    "        for k in range(len(Big_arr[j][i])):\n",
    "            index = Big_datearr[j][i][k]-1984\n",
    "            if Year.get(str(index)) == None:\n",
    "                Year[str(index)] = []\n",
    "            Year[str(index)].append(Big_arr[j][i][k-1])\n",
    "    List_year = []\n",
    "    for v, key in enumerate(Year):\n",
    "        List_year.append(np.mean(Year[key]))\n",
    "    Big_Percent.append(List_year[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Barz = []\n",
    "\n",
    "for i in range(len(Big_Percent)):\n",
    "    temp = []\n",
    "    for j in range(len(Big_Percent[i])):\n",
    "        temp.append(100*(Big_Percent[i][j]-Big_Percent[i][0])/Big_Percent[i][0])\n",
    "    Barz.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=(10, 12))\n",
    "for i in range(len(Barz)):\n",
    "    axs.barh(np.arange(len(Barz[i]))+(i/5), Barz[i], align='center',height= 0.2,color=colours[i],label='Transects: '+str(transect_range[i][0])+\"-\"+str(transect_range[i][1]) )\n",
    "axs.plot([0]*100,np.arange(0,37,0.37),'-.',color='k')\n",
    "axs.set_xlabel(\"% Change Since 1984\")\n",
    "#axs.set_xlim(-500,500)\n",
    "axs.set_yticks(np.arange(0,37,1))\n",
    "#axs.set_yticklabels(list(np.array(d)[NaN_mask]))\n",
    "fig.text(0.25,0.85,\"Accretion (Relative to 1984)\")\n",
    "fig.text(0.58,0.85,\"Erosion (Relative to 1984)\")\n",
    "axs.legend(loc='lower right')\n",
    "for i in range(37):\n",
    "    axs.plot(np.arange(-500,500,10),[i-0.1]*100,'-.',color='k',alpha=0.7,linewidth=0.45)\n",
    "fig.savefig(os.path.join('Data/' + sitename + '/jpg_files/barBreakdown.jpg'), dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, output_latlon, output_proj = VegetationLine.extract_veglines(settings, metadata, sat_list, polygon)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
